{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment SetUP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./torch_cluster-1.6.1-cp310-cp310-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-cluster==1.6.1) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-cluster==1.6.1) (1.23.5)\n",
      "Installing collected packages: torch-cluster\n",
      "  Attempting uninstall: torch-cluster\n",
      "    Found existing installation: torch-cluster 1.6.3+pt20cu118\n",
      "    Uninstalling torch-cluster-1.6.3+pt20cu118:\n",
      "      Successfully uninstalled torch-cluster-1.6.3+pt20cu118\n",
      "Successfully installed torch-cluster-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing ./torch_geometric-2.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (4.66.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.11.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (3.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (5.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric==2.3.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric==2.3.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric==2.3.1) (3.1.0)\n",
      "Installing collected packages: torch-geometric\n",
      "  Attempting uninstall: torch-geometric\n",
      "    Found existing installation: torch_geometric 2.4.0\n",
      "    Uninstalling torch_geometric-2.4.0:\n",
      "      Successfully uninstalled torch_geometric-2.4.0\n",
      "Successfully installed torch-geometric-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing ./torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl\n",
      "Installing collected packages: torch-scatter\n",
      "  Attempting uninstall: torch-scatter\n",
      "    Found existing installation: torch-scatter 2.1.2+pt20cu118\n",
      "    Uninstalling torch-scatter-2.1.2+pt20cu118:\n",
      "      Successfully uninstalled torch-scatter-2.1.2+pt20cu118\n",
      "Successfully installed torch-scatter-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing ./torch_sparse-0.6.17-cp310-cp310-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse==0.6.17) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-sparse==0.6.17) (1.23.5)\n",
      "Installing collected packages: torch-sparse\n",
      "  Attempting uninstall: torch-sparse\n",
      "    Found existing installation: torch-sparse 0.6.18+pt20cu118\n",
      "    Uninstalling torch-sparse-0.6.18+pt20cu118:\n",
      "      Successfully uninstalled torch-sparse-0.6.18+pt20cu118\n",
      "Successfully installed torch-sparse-0.6.17\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing ./torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl\n",
      "Installing collected packages: torch-spline-conv\n",
      "  Attempting uninstall: torch-spline-conv\n",
      "    Found existing installation: torch-spline-conv 1.2.2+pt20cu118\n",
      "    Uninstalling torch-spline-conv-1.2.2+pt20cu118:\n",
      "      Successfully uninstalled torch-spline-conv-1.2.2+pt20cu118\n",
      "Successfully installed torch-spline-conv-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch_cluster-1.6.1-cp310-cp310-linux_x86_64.whl\n",
    "%pip install torch_geometric-2.3.1-py3-none-any.whl\n",
    "%pip install torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl\n",
    "%pip install torch_sparse-0.6.17-cp310-cp310-linux_x86_64.whl\n",
    "%pip install torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:18: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZNK5torch8autograd4Node4nameEv\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZNK5torch8autograd4Node4nameEv\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn, sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, aggr\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(directory):\n",
    "    splits = [\"train\", \"valid\", \"test\"]\n",
    "    dfs = dict()\n",
    "\n",
    "    for split in splits:\n",
    "        path = os.path.join(directory, split)\n",
    "        files = os.listdir(path)\n",
    "        list_df = []\n",
    "\n",
    "        for file in files:\n",
    "            d = dict(np.load(os.path.join(path, file)))\n",
    "            d[\"file\"] = file\n",
    "            list_df.append(d)\n",
    "        dfs[split] = pd.DataFrame.from_dict(list_df)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "tile_xla = load_df(\"./data/tpugraphs/npz_all/npz/tile/xla/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_feat</th>\n",
       "      <th>node_opcode</th>\n",
       "      <th>edge_index</th>\n",
       "      <th>config_feat</th>\n",
       "      <th>config_runtime</th>\n",
       "      <th>config_runtime_normalizers</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 11, 63, 11, 63, 41, 63, 41, 26, 63, 63, 41]</td>\n",
       "      <td>[[1, 0], [3, 2], [5, 1], [5, 4], [7, 3], [7, 6...</td>\n",
       "      <td>[[32.0, 32.0, 0.0, 0.0, 0.0, 0.0, 64.0, 1024.0...</td>\n",
       "      <td>[263238, 2029255, 1192602, 1027600, 1962135, 5...</td>\n",
       "      <td>[263238, 263238, 263238, 263238, 263238, 26323...</td>\n",
       "      <td>alexnet_train_batch_32_-1bae27a41d70f4dc.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[24, 13, 48, 87, 63, 13, 25, 52, 25, 63, 24, 1...</td>\n",
       "      <td>[[1, 0], [3, 1], [3, 2], [5, 4], [6, 5], [7, 3...</td>\n",
       "      <td>[[6.0, 12.0, 2.0, 2.0, 0.0, 0.0, 22.0, 288.0, ...</td>\n",
       "      <td>[155012, 3950817, 2048285, 1528077, 682642, 77...</td>\n",
       "      <td>[155012, 155012, 155012, 155012, 155012, 15501...</td>\n",
       "      <td>alexnet_train_batch_32_-21d9f3b8c41eb3e3.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 11, 63, 11, 63, 63, 13, 63, 41, 63, 41, 2...</td>\n",
       "      <td>[[1, 0], [3, 2], [6, 5], [8, 1], [8, 7], [10, ...</td>\n",
       "      <td>[[3.0, 12.0, 4.0, 3.0, 0.0, 0.0, 22.0, 432.0, ...</td>\n",
       "      <td>[113020, 667977, 966760, 5897798, 1554171, 308...</td>\n",
       "      <td>[113020, 113020, 113020, 113020, 113020, 11302...</td>\n",
       "      <td>alexnet_train_batch_32_-282ddd3271de7d28.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 63, 2, 24, 13, 48, 87, 63, 13, 25, 52, 25...</td>\n",
       "      <td>[[2, 0], [2, 1], [4, 3], [6, 4], [6, 5], [8, 7...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0,...</td>\n",
       "      <td>[13580, 35675, 63934, 62597, 40362, 27707, 319...</td>\n",
       "      <td>[13580, 13580, 13580, 13580, 13580, 13580, 135...</td>\n",
       "      <td>alexnet_train_batch_32_-3545610a073feea6.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 63, 2, 63, 11, 63, 11, 24, 13, 48, 87, 63...</td>\n",
       "      <td>[[2, 0], [2, 1], [4, 3], [6, 5], [8, 7], [10, ...</td>\n",
       "      <td>[[3.0, 3.0, 16.0, 3.0, 0.0, 0.0, 25.0, 432.0, ...</td>\n",
       "      <td>[216908, 5999505, 14326342, 861357, 1297804, 2...</td>\n",
       "      <td>[216908, 216908, 216908, 216908, 216908, 21690...</td>\n",
       "      <td>alexnet_train_batch_32_-444744203bcb5069.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 63, 13, 95, 63, 13, 59, 63, 13, 59, 63, 1...</td>\n",
       "      <td>[[2, 1], [3, 0], [3, 2], [5, 4], [6, 3], [6, 5...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0...</td>\n",
       "      <td>[284464, 270720, 892307, 324908, 294581, 59365...</td>\n",
       "      <td>[284464, 284464, 284464, 284464, 284464, 28446...</td>\n",
       "      <td>xception_imagenet_754825b353c7974f.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 13, 63, 24, 13, 59, 63, 13, 95, 63, 13, 6...</td>\n",
       "      <td>[[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...</td>\n",
       "      <td>[[8.0, 37.0, 2.0, 1.0, 0.0, 0.0, 48.0, 592.0, ...</td>\n",
       "      <td>[638608, 11962432, 6114872, 7372895, 5149337, ...</td>\n",
       "      <td>[638608, 638608, 638608, 638608, 638608, 63860...</td>\n",
       "      <td>xception_imagenet_7560f673e5820c82.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 13, 63, 63, 13, 95, 63, 13, 59, 63, 13, 5...</td>\n",
       "      <td>[[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...</td>\n",
       "      <td>[[7.0, 7.0, 2.0, 4.0, 0.0, 0.0, 20.0, 392.0, 1...</td>\n",
       "      <td>[244198, 7123302, 4481747, 1745201, 1627652, 8...</td>\n",
       "      <td>[244198, 244198, 244198, 244198, 244198, 24419...</td>\n",
       "      <td>xception_imagenet_7720f6dabe293cfe.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 13, 63, 24, 13, 59, 63, 13, 95, 63, 13, 6...</td>\n",
       "      <td>[[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...</td>\n",
       "      <td>[[1.0, 28.0, 2.0, 2.0, 0.0, 0.0, 33.0, 112.0, ...</td>\n",
       "      <td>[95785, 807268, 437115, 220154, 264825, 179818...</td>\n",
       "      <td>[95785, 95785, 95785, 95785, 95785, 95785, 957...</td>\n",
       "      <td>xception_imagenet_7eaa46ca4812dfb2.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 13, 63, 24, 13, 59, 63, 13, 95, 63, 13, 6...</td>\n",
       "      <td>[[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...</td>\n",
       "      <td>[[1.0, 1.0, 8.0, 1.0, 0.0, 0.0, 11.0, 8.0, 2.0...</td>\n",
       "      <td>[637227, 1569948, 1797120, 1558561, 775711, 90...</td>\n",
       "      <td>[637227, 637227, 637227, 637227, 637227, 63722...</td>\n",
       "      <td>xception_imagenet_9b1704c883ceb0d.npz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5709 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              node_feat  \\\n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                 ...   \n",
       "5704  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5705  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5706  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5707  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5708  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                            node_opcode  \\\n",
       "0      [63, 11, 63, 11, 63, 41, 63, 41, 26, 63, 63, 41]   \n",
       "1     [24, 13, 48, 87, 63, 13, 25, 52, 25, 63, 24, 1...   \n",
       "2     [63, 11, 63, 11, 63, 63, 13, 63, 41, 63, 41, 2...   \n",
       "3     [63, 63, 2, 24, 13, 48, 87, 63, 13, 25, 52, 25...   \n",
       "4     [63, 63, 2, 63, 11, 63, 11, 24, 13, 48, 87, 63...   \n",
       "...                                                 ...   \n",
       "5704  [63, 63, 13, 95, 63, 13, 59, 63, 13, 59, 63, 1...   \n",
       "5705  [63, 13, 63, 24, 13, 59, 63, 13, 95, 63, 13, 6...   \n",
       "5706  [63, 13, 63, 63, 13, 95, 63, 13, 59, 63, 13, 5...   \n",
       "5707  [63, 13, 63, 24, 13, 59, 63, 13, 95, 63, 13, 6...   \n",
       "5708  [63, 13, 63, 24, 13, 59, 63, 13, 95, 63, 13, 6...   \n",
       "\n",
       "                                             edge_index  \\\n",
       "0     [[1, 0], [3, 2], [5, 1], [5, 4], [7, 3], [7, 6...   \n",
       "1     [[1, 0], [3, 1], [3, 2], [5, 4], [6, 5], [7, 3...   \n",
       "2     [[1, 0], [3, 2], [6, 5], [8, 1], [8, 7], [10, ...   \n",
       "3     [[2, 0], [2, 1], [4, 3], [6, 4], [6, 5], [8, 7...   \n",
       "4     [[2, 0], [2, 1], [4, 3], [6, 5], [8, 7], [10, ...   \n",
       "...                                                 ...   \n",
       "5704  [[2, 1], [3, 0], [3, 2], [5, 4], [6, 3], [6, 5...   \n",
       "5705  [[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...   \n",
       "5706  [[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...   \n",
       "5707  [[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...   \n",
       "5708  [[1, 0], [4, 3], [5, 2], [5, 4], [7, 6], [8, 5...   \n",
       "\n",
       "                                            config_feat  \\\n",
       "0     [[32.0, 32.0, 0.0, 0.0, 0.0, 0.0, 64.0, 1024.0...   \n",
       "1     [[6.0, 12.0, 2.0, 2.0, 0.0, 0.0, 22.0, 288.0, ...   \n",
       "2     [[3.0, 12.0, 4.0, 3.0, 0.0, 0.0, 22.0, 432.0, ...   \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0,...   \n",
       "4     [[3.0, 3.0, 16.0, 3.0, 0.0, 0.0, 25.0, 432.0, ...   \n",
       "...                                                 ...   \n",
       "5704  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0...   \n",
       "5705  [[8.0, 37.0, 2.0, 1.0, 0.0, 0.0, 48.0, 592.0, ...   \n",
       "5706  [[7.0, 7.0, 2.0, 4.0, 0.0, 0.0, 20.0, 392.0, 1...   \n",
       "5707  [[1.0, 28.0, 2.0, 2.0, 0.0, 0.0, 33.0, 112.0, ...   \n",
       "5708  [[1.0, 1.0, 8.0, 1.0, 0.0, 0.0, 11.0, 8.0, 2.0...   \n",
       "\n",
       "                                         config_runtime  \\\n",
       "0     [263238, 2029255, 1192602, 1027600, 1962135, 5...   \n",
       "1     [155012, 3950817, 2048285, 1528077, 682642, 77...   \n",
       "2     [113020, 667977, 966760, 5897798, 1554171, 308...   \n",
       "3     [13580, 35675, 63934, 62597, 40362, 27707, 319...   \n",
       "4     [216908, 5999505, 14326342, 861357, 1297804, 2...   \n",
       "...                                                 ...   \n",
       "5704  [284464, 270720, 892307, 324908, 294581, 59365...   \n",
       "5705  [638608, 11962432, 6114872, 7372895, 5149337, ...   \n",
       "5706  [244198, 7123302, 4481747, 1745201, 1627652, 8...   \n",
       "5707  [95785, 807268, 437115, 220154, 264825, 179818...   \n",
       "5708  [637227, 1569948, 1797120, 1558561, 775711, 90...   \n",
       "\n",
       "                             config_runtime_normalizers  \\\n",
       "0     [263238, 263238, 263238, 263238, 263238, 26323...   \n",
       "1     [155012, 155012, 155012, 155012, 155012, 15501...   \n",
       "2     [113020, 113020, 113020, 113020, 113020, 11302...   \n",
       "3     [13580, 13580, 13580, 13580, 13580, 13580, 135...   \n",
       "4     [216908, 216908, 216908, 216908, 216908, 21690...   \n",
       "...                                                 ...   \n",
       "5704  [284464, 284464, 284464, 284464, 284464, 28446...   \n",
       "5705  [638608, 638608, 638608, 638608, 638608, 63860...   \n",
       "5706  [244198, 244198, 244198, 244198, 244198, 24419...   \n",
       "5707  [95785, 95785, 95785, 95785, 95785, 95785, 957...   \n",
       "5708  [637227, 637227, 637227, 637227, 637227, 63722...   \n",
       "\n",
       "                                              file  \n",
       "0     alexnet_train_batch_32_-1bae27a41d70f4dc.npz  \n",
       "1     alexnet_train_batch_32_-21d9f3b8c41eb3e3.npz  \n",
       "2     alexnet_train_batch_32_-282ddd3271de7d28.npz  \n",
       "3     alexnet_train_batch_32_-3545610a073feea6.npz  \n",
       "4     alexnet_train_batch_32_-444744203bcb5069.npz  \n",
       "...                                            ...  \n",
       "5704        xception_imagenet_754825b353c7974f.npz  \n",
       "5705        xception_imagenet_7560f673e5820c82.npz  \n",
       "5706        xception_imagenet_7720f6dabe293cfe.npz  \n",
       "5707        xception_imagenet_7eaa46ca4812dfb2.npz  \n",
       "5708         xception_imagenet_9b1704c883ceb0d.npz  \n",
       "\n",
       "[5709 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_xla[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_edge_list_to_file(edges, filename):\n",
    "    with open(filename, \"w\") as file:\n",
    "        for edge in edges:\n",
    "            file.write(f\"{edge[0]} {edge[1]}\\n\")\n",
    "\n",
    "\n",
    "write_edge_list_to_file(edge_list, \"edge_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(\"all_edge_list\"):\n",
    "    os.makedirs(\"all_edge_list\")\n",
    "\n",
    "for i, edge in enumerate(edge_list):\n",
    "    write_edge_list_to_file(edge, f\"./all_edge_list/edge_list_{i}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile_xla['valid'].loc[0, 'config_runtime']/(tile_xla['valid'].loc[0, 'config_runtime_normalizers'] + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_OP_CODES = 120  # Number of node operation codes\n",
    "# opcode padding value 121\n",
    "NODE_FEATS = 140  # Number of node features\n",
    "CONFIG_FEATS = 24  # Number of configuration features\n",
    "NODE_CONFIG_FEATS = 18  # Number of combined node and configuration featueres\n",
    "STRECHING_CONSTANT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  8,  9, 10,  5,  7,  1,  4,  3,  6,  0,  2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def topological_sort(graph_edges):\n",
    "    G = nx.DiGraph(graph_edges)\n",
    "    return np.array(list(nx.topological_sort(G)))\n",
    "\n",
    "\n",
    "topological_sort([tuple(edge) for edge in tile_xla[\"train\"][\"edge_index\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileDataset(Dataset):\n",
    "    def __init__(self, df, n=STRECHING_CONSTANT, reverse=False):\n",
    "        self.df = df\n",
    "        self.streching_constant = n\n",
    "        self.reverse = reverse\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        config_feat = torch.tensor(row[\"config_feat\"].astype(np.float32))\n",
    "        node_feat = torch.tensor(row[\"node_feat\"].astype(np.float32))\n",
    "        node_opcode = torch.tensor(row[\"node_opcode\"].astype(np.int64))\n",
    "        if self.reverse:\n",
    "            node_sequence = torch.tensor(\n",
    "                np.flip(\n",
    "                    topological_sort([tuple(edge) for edge in row[\"edge_index\"]])\n",
    "                ).astype(np.int64)\n",
    "            )\n",
    "        else:\n",
    "            node_sequence = torch.tensor(\n",
    "                topological_sort([tuple(edge) for edge in row[\"edge_index\"]]).astype(\n",
    "                    np.int64\n",
    "                )\n",
    "            )\n",
    "        # edge_index = torch.tensor(np.swapaxes(row[\"edge_index\"], 0, 1).astype(np.int64))\n",
    "        target = (\n",
    "            row[\"config_runtime\"] / (row[\"config_runtime_normalizers\"] + 1e-5)\n",
    "        ).astype(np.float32)\n",
    "        # minmax scale the target, we only care about order\n",
    "        # target = (\n",
    "        #     (target - np.min(target))\n",
    "        #     / (np.max(target) - np.min(target) + 1e-5)\n",
    "        #     * self.streching_constant\n",
    "        # )\n",
    "        target = torch.tensor(target)\n",
    "        return config_feat, node_feat, node_opcode, node_sequence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    config_feats, node_feats, node_opcodes, node_sequences, targets = zip(*batch)\n",
    "\n",
    "    bs = len(config_feats)  # batch_size\n",
    "    max_len_config = max([config_feat.shape[0] for config_feat in config_feats])\n",
    "    max_len_node = max([len(node_sequence) for node_sequence in node_sequences])\n",
    "\n",
    "    padded_config = torch.zeros(bs, max_len_config, config_feats[0].shape[-1])\n",
    "    padded_target = torch.zeros(bs, max_len_config)\n",
    "    padded_feat = torch.zeros(bs, max_len_node, node_feats[0].shape[-1])\n",
    "    padded_opcode = torch.ones(bs, max_len_node) * 121  # opcode padding value\n",
    "    padded_sequence = torch.ones(bs, max_len_node) * -1  # not a valid node index\n",
    "    config_mask = torch.zeros(bs, max_len_config)\n",
    "\n",
    "    for idx, (config_feat, node_feat, node_opcode, node_sequence, target) in enumerate(\n",
    "        batch\n",
    "    ):\n",
    "        padded_config[idx, : config_feat.shape[0]] = config_feat\n",
    "        padded_target[idx, : target.shape[0]] = target\n",
    "        config_mask[idx, : target.shape[0]] = 1\n",
    "        padded_feat[idx, : node_feat.shape[0]] = node_feat\n",
    "        padded_opcode[idx, : node_opcode.shape[0]] = node_opcode\n",
    "        padded_sequence[idx, : node_sequence.shape[0]] = node_sequence\n",
    "\n",
    "    return (\n",
    "        padded_sequence.to(torch.int64),\n",
    "        padded_opcode.to(torch.int64),\n",
    "        padded_feat,\n",
    "        padded_config,\n",
    "        config_mask,\n",
    "        padded_target,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3587e-04, 6.5726e-01, 3.4595e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.0426e-04, 2.3086e-01, 1.1530e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.1099e-05, 3.6438e-02, 5.6050e-02,  ..., 2.3217e-03, 5.2476e-03,\n",
      "         4.8365e-04],\n",
      "        [4.3841e-03, 1.1808e-01, 2.6349e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "for (\n",
    "    padded_sequence,\n",
    "    padded_opcode,\n",
    "    padded_feat,\n",
    "    padded_config,\n",
    "    config_mask,\n",
    "    padded_target,\n",
    ") in train_loader:\n",
    "    gather_indices = torch.where(\n",
    "        padded_sequence == -1, torch.zeros_like(padded_sequence), padded_sequence\n",
    "    )\n",
    "    print(padded_target)\n",
    "    # print(gather_indices.unsqueeze(-1).expand(-1, -1, padded_feat.shape[-1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.op_embedding_dim = embedding_dim\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            NODE_OP_CODES, self.op_embedding_dim, padding_idx=121\n",
    "        )\n",
    "\n",
    "    def forward(self, node_sequence, node_opcode, node_feat, configs, config_mask):\n",
    "        node_features = torch.concat(\n",
    "            [node_feat, self.embedding(node_opcode)], dim=-1\n",
    "        )  # [bs, # of nodes, feat_dim]\n",
    "        # node_features = self.pre_net(node_features)\n",
    "        gather_indices = torch.where(\n",
    "            node_sequence == -1, torch.zeros_like(node_sequence), node_sequence\n",
    "        )\n",
    "        sequence = torch.gather(\n",
    "            node_features,\n",
    "            1,\n",
    "            gather_indices.unsqueeze(-1).expand(-1, -1, node_features.shape[-1]),\n",
    "        )\n",
    "        mask = (node_sequence != -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TileDataset(tile_xla[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=8, shuffle=True, collate_fn=custom_collate\n",
    ")\n",
    "# train_loader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels,\n",
    "        embedding_dim,\n",
    "        graph_in,\n",
    "        graph_out,\n",
    "        hidden_dim,\n",
    "        activation_fn,\n",
    "        dropout=0.0,\n",
    "        n=STRECHING_CONSTANT,\n",
    "        aggregator=aggr.MultiAggregation,\n",
    "    ):\n",
    "        assert len(hidden_channels) > 0\n",
    "        super().__init__()\n",
    "        self.op_embedding_dim = embedding_dim  # I choose 4-dimensional embedding\n",
    "        self.node_dim = graph_in\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation_fn = activation_fn\n",
    "        self.dropout = dropout\n",
    "        self.streching_constant = n\n",
    "        self.agg = aggregator\n",
    "        self.gnn_conv = SAGEConv\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            NODE_OP_CODES,\n",
    "            self.op_embedding_dim,\n",
    "        )\n",
    "        self.pre_net = torch.nn.Sequential(\n",
    "            nn.Linear(self.op_embedding_dim + NODE_FEATS, self.hidden_dim),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            self.activation_fn(),\n",
    "            nn.Linear(self.hidden_dim, self.node_dim),\n",
    "        )\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        aggr1 = self.agg(\n",
    "            aggrs=[\"mean\", \"std\"],\n",
    "            mode=\"attn\",\n",
    "            mode_kwargs=dict(\n",
    "                in_channels=self.node_dim, out_channels=hidden_channels[0], num_heads=4\n",
    "            ),\n",
    "        )\n",
    "        self.convs.append(self.gnn_conv(self.node_dim, hidden_channels[0]))\n",
    "        for i in range(len(hidden_channels) - 1):\n",
    "            aggr2 = self.agg(\n",
    "                aggrs=[\"mean\", \"std\"],\n",
    "                mode=\"attn\",\n",
    "                mode_kwargs=dict(\n",
    "                    in_channels=hidden_channels[i],\n",
    "                    out_channels=hidden_channels[i + 1],\n",
    "                    num_heads=4,\n",
    "                ),\n",
    "            )\n",
    "            self.convs.append(self.gnn_conv(hidden_channels[i], hidden_channels[i + 1]))\n",
    "        aggr3 = self.agg(\n",
    "            aggrs=[\"mean\", \"std\"],\n",
    "            mode=\"attn\",\n",
    "            mode_kwargs=dict(\n",
    "                in_channels=hidden_channels[-1], out_channels=graph_out, num_heads=4\n",
    "            ),\n",
    "        )\n",
    "        self.convs.append(self.gnn_conv(hidden_channels[-1], graph_out))\n",
    "\n",
    "        self.post_net = torch.nn.Sequential(\n",
    "            nn.Linear(graph_out * 2 + 24, self.hidden_dim),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    #         self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(\n",
    "        self, x_cfg: Tensor, x_feat: Tensor, x_op: Tensor, edge_index: Tensor\n",
    "    ) -> Tensor:\n",
    "        # get graph features\n",
    "        x = torch.concat([x_feat, self.embedding(x_op)], dim=1)\n",
    "        x = self.pre_net(x)\n",
    "        # pass though conv layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index).relu()\n",
    "        # get 1d graph embedding using average pooling\n",
    "        x_mean = x.mean(0)\n",
    "        x_max = x.max(0).values\n",
    "\n",
    "        # put graph data into config data\n",
    "        x = torch.concat(\n",
    "            [x_cfg, x_max.repeat((len(x_cfg), 1)), x_mean.repeat((len(x_cfg), 1))],\n",
    "            axis=1,\n",
    "        )\n",
    "        # put into dense nn\n",
    "        x = torch.flatten(self.post_net(x))\n",
    "        x = (\n",
    "            (x - torch.min(x))\n",
    "            / (torch.max(x) - torch.min(x) + 1e-5)\n",
    "            * self.streching_constant\n",
    "        )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_tile_mean(predictions, df):\n",
    "    score = 0\n",
    "    for i in range(len(df)):\n",
    "        predbest = np.mean(df.iloc[i][\"config_runtime\"][predictions[i]])\n",
    "        best = np.mean(np.sort(df.iloc[i][\"config_runtime\"])[:50])\n",
    "        score += 2 - predbest / best\n",
    "    score /= len(df)\n",
    "    return score\n",
    "\n",
    "\n",
    "def score_tile_max(predictions, df):\n",
    "    score = 0\n",
    "    for i in range(len(df)):\n",
    "        predbest = np.min(df.iloc[i][\"config_runtime\"][predictions[i][:5]])\n",
    "        best = np.min(df.iloc[i][\"config_runtime\"])\n",
    "        #         print(best,predbest)\n",
    "        score += 2 - predbest / best\n",
    "    score /= len(df)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWeightedMSELoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-6):\n",
    "        super(CustomWeightedMSELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.mse_loss = nn.MSELoss(\n",
    "            reduction=\"none\"\n",
    "        )  # We will handle the reduction ourselves\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Calculate the weights based on the true values\n",
    "        weights = 1 / (y_true + self.epsilon)  # Add epsilon to avoid division by zero\n",
    "        # Calculate the per-element squared error\n",
    "        per_element_loss = self.mse_loss(y_pred, y_true)\n",
    "        # Apply the weights and calculate the mean loss\n",
    "        weighted_loss = weights * per_element_loss\n",
    "        loss = torch.mean(weighted_loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMarginRankingLoss(nn.Module):\n",
    "    def __init__(self, margin=0.0, reduction=\"none\"):\n",
    "        super(CustomMarginRankingLoss, self).__init__()\n",
    "        self.loss = nn.MarginRankingLoss(margin=margin, reduction=reduction)\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        true = y_true.view(y_true.shape[0], -1).half()\n",
    "        pred = y_pred.view(y_pred.shape[0], -1).half()\n",
    "        true_diffs = true - true.T\n",
    "        pred_diffs = pred - pred.T\n",
    "        s_ij = torch.sign(true_diffs).to(device)\n",
    "        s_ij.fill_diagonal_(0)\n",
    "        pred_diffs.fill_diagonal_(0)\n",
    "        cost = self.loss(pred_diffs, torch.zeros_like(pred_diffs), s_ij)\n",
    "        cost = cost[s_ij != 0].mean()\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(\n",
    "    hidden_channels=[32, 48, 64, 84],\n",
    "    embedding_dim=32,\n",
    "    graph_in=64,\n",
    "    graph_out=64,\n",
    "    hidden_dim=128,\n",
    "    activation_fn=nn.ReLU,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "train_dataset = TileDataset(tile_xla[\"train\"])\n",
    "val_dataset = TileDataset(tile_xla[\"valid\"])\n",
    "criterion = CustomWeightedMSELoss()\n",
    "epochs = 20\n",
    "steps = len(train_dataset) * epochs\n",
    "warmup_steps = int(steps * 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = CosineLRScheduler(\n",
    "    optimizer,\n",
    "    t_initial=steps,\n",
    "    warmup_t=warmup_steps,\n",
    "    warmup_lr_init=1e-6,\n",
    "    lr_min=2e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((tile_xla[\"train\"], tile_xla[\"valid\"]), axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 0, comp_score = 0.518, mean_score = 0.147,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 1, comp_score = -0.933, mean_score = -2.074,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 2, comp_score = 0.971, mean_score = 0.227,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 3, comp_score = 0.969, mean_score = 0.200,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 4, comp_score = 0.969, mean_score = 0.324,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 5, comp_score = 0.961, mean_score = 0.178,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 6, comp_score = 0.969, mean_score = 0.323,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 7, comp_score = 0.936, mean_score = 0.474,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 8, comp_score = 0.970, mean_score = 0.369,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 9, comp_score = 0.919, mean_score = 0.468,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 10, comp_score = 0.950, mean_score = 0.446,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 11, comp_score = 0.494, mean_score = 0.331,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 12, comp_score = 0.910, mean_score = 0.576,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 13, comp_score = 0.931, mean_score = 0.525,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 14, comp_score = 0.934, mean_score = 0.521,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 0, comp_score = 0.421, mean_score = 0.104,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 1, comp_score = 0.970, mean_score = -1.187,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 2, comp_score = 0.966, mean_score = 0.147,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 3, comp_score = 0.971, mean_score = 0.252,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 4, comp_score = 0.967, mean_score = 0.171,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 5, comp_score = 0.963, mean_score = 0.227,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 6, comp_score = 0.961, mean_score = 0.309,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 7, comp_score = 0.960, mean_score = 0.298,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 8, comp_score = 0.974, mean_score = 0.288,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 9, comp_score = 0.921, mean_score = 0.474,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 10, comp_score = 0.929, mean_score = 0.491,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 11, comp_score = 0.932, mean_score = 0.628,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 12, comp_score = 0.945, mean_score = 0.520,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 13, comp_score = 0.950, mean_score = 0.547,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 epoch 14, comp_score = 0.937, mean_score = 0.559,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 0, comp_score = 0.438, mean_score = 0.005,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 1, comp_score = 0.971, mean_score = -1.216,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 2, comp_score = 0.962, mean_score = 0.242,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 3, comp_score = 0.952, mean_score = 0.278,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 4, comp_score = 0.963, mean_score = 0.193,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 5, comp_score = 0.968, mean_score = 0.111,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 6, comp_score = 0.957, mean_score = 0.407,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 7, comp_score = 0.963, mean_score = 0.323,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 8, comp_score = 0.906, mean_score = 0.674,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 9, comp_score = 0.943, mean_score = 0.476,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 10, comp_score = 0.958, mean_score = 0.383,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 11, comp_score = 0.957, mean_score = 0.414,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 12, comp_score = 0.899, mean_score = 0.520,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 13, comp_score = 0.917, mean_score = 0.573,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 epoch 14, comp_score = 0.911, mean_score = 0.539,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 0, comp_score = -0.328, mean_score = -0.308,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 1, comp_score = 0.969, mean_score = -1.325,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 2, comp_score = 0.961, mean_score = 0.180,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 3, comp_score = 0.956, mean_score = 0.159,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 4, comp_score = 0.961, mean_score = 0.157,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 5, comp_score = 0.963, mean_score = 0.049,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 6, comp_score = 0.959, mean_score = 0.097,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 7, comp_score = 0.902, mean_score = 0.395,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 8, comp_score = 0.958, mean_score = 0.304,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 9, comp_score = 0.963, mean_score = 0.256,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 10, comp_score = 0.948, mean_score = 0.392,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 11, comp_score = 0.955, mean_score = 0.387,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 12, comp_score = 0.914, mean_score = 0.509,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 13, comp_score = 0.932, mean_score = 0.525,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 epoch 14, comp_score = 0.875, mean_score = 0.621,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 0, comp_score = -1.500, mean_score = -1.318,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 1, comp_score = 0.968, mean_score = -0.504,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 2, comp_score = 0.960, mean_score = 0.251,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 3, comp_score = 0.967, mean_score = 0.179,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 4, comp_score = 0.963, mean_score = 0.308,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 5, comp_score = 0.920, mean_score = 0.554,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 6, comp_score = 0.954, mean_score = 0.388,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 7, comp_score = 0.956, mean_score = 0.441,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 8, comp_score = 0.929, mean_score = 0.585,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 9, comp_score = 0.923, mean_score = 0.631,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 10, comp_score = 0.887, mean_score = 0.524,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 11, comp_score = 0.943, mean_score = 0.579,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 12, comp_score = 0.902, mean_score = 0.578,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 13, comp_score = 0.937, mean_score = 0.578,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 epoch 14, comp_score = 0.939, mean_score = 0.550,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 0, comp_score = 0.536, mean_score = 0.158,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 1, comp_score = 0.941, mean_score = 0.564,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 2, comp_score = 0.967, mean_score = 0.157,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 3, comp_score = 0.974, mean_score = 0.028,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 4, comp_score = 0.963, mean_score = 0.168,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 5, comp_score = 0.970, mean_score = 0.132,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 6, comp_score = 0.693, mean_score = 0.448,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 7, comp_score = 0.961, mean_score = 0.371,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 8, comp_score = 0.923, mean_score = 0.482,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 9, comp_score = 0.963, mean_score = 0.392,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 10, comp_score = 0.950, mean_score = 0.525,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 11, comp_score = 0.924, mean_score = 0.554,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 12, comp_score = 0.946, mean_score = 0.541,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 13, comp_score = 0.947, mean_score = 0.602,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 epoch 14, comp_score = 0.929, mean_score = 0.600,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 0, comp_score = 0.545, mean_score = 0.159,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 1, comp_score = 0.971, mean_score = -0.419,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 2, comp_score = 0.965, mean_score = 0.126,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 3, comp_score = 0.925, mean_score = 0.445,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 4, comp_score = 0.964, mean_score = 0.164,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 5, comp_score = 0.954, mean_score = 0.338,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 6, comp_score = 0.949, mean_score = 0.487,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 7, comp_score = 0.963, mean_score = 0.224,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 8, comp_score = 0.960, mean_score = 0.271,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 9, comp_score = 0.923, mean_score = 0.524,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 10, comp_score = 0.938, mean_score = 0.496,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 11, comp_score = 0.921, mean_score = 0.589,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 12, comp_score = 0.939, mean_score = 0.561,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 13, comp_score = 0.946, mean_score = 0.588,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 epoch 14, comp_score = 0.932, mean_score = 0.576,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 0, comp_score = 0.544, mean_score = 0.237,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 1, comp_score = 0.973, mean_score = -0.954,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 2, comp_score = 0.965, mean_score = 0.202,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 3, comp_score = 0.931, mean_score = 0.489,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 4, comp_score = 0.964, mean_score = 0.317,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 5, comp_score = 0.623, mean_score = 0.350,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 6, comp_score = 0.911, mean_score = 0.556,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 7, comp_score = 0.917, mean_score = 0.585,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 8, comp_score = 0.953, mean_score = 0.418,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 9, comp_score = 0.903, mean_score = 0.497,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 10, comp_score = 0.948, mean_score = 0.492,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 11, comp_score = 0.938, mean_score = 0.523,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 12, comp_score = 0.938, mean_score = 0.544,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 13, comp_score = 0.931, mean_score = 0.567,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 epoch 14, comp_score = 0.899, mean_score = 0.557,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 0, comp_score = 0.453, mean_score = 0.172,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 1, comp_score = 0.973, mean_score = -1.206,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 2, comp_score = 0.969, mean_score = -0.089,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 3, comp_score = 0.951, mean_score = 0.202,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 4, comp_score = 0.961, mean_score = 0.137,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 5, comp_score = 0.907, mean_score = 0.508,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 6, comp_score = 0.965, mean_score = 0.088,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 7, comp_score = 0.937, mean_score = 0.421,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 8, comp_score = 0.957, mean_score = 0.341,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 9, comp_score = 0.956, mean_score = 0.444,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 10, comp_score = 0.939, mean_score = 0.420,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 11, comp_score = 0.724, mean_score = 0.561,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 12, comp_score = 0.922, mean_score = 0.547,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 13, comp_score = 0.926, mean_score = 0.586,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 epoch 14, comp_score = 0.796, mean_score = 0.547,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 0, comp_score = 0.630, mean_score = 0.313,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 1, comp_score = 0.971, mean_score = -0.459,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 2, comp_score = 0.964, mean_score = 0.171,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 3, comp_score = 0.961, mean_score = 0.466,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 4, comp_score = 0.969, mean_score = 0.283,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 5, comp_score = 0.968, mean_score = 0.346,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 6, comp_score = 0.967, mean_score = 0.179,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 7, comp_score = 0.953, mean_score = 0.506,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 8, comp_score = 0.962, mean_score = 0.427,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 9, comp_score = 0.967, mean_score = 0.397,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 10, comp_score = 0.938, mean_score = 0.514,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 11, comp_score = 0.936, mean_score = 0.566,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 12, comp_score = 0.700, mean_score = 0.540,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 13, comp_score = 0.934, mean_score = 0.613,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 epoch 14, comp_score = 0.940, mean_score = 0.615,\n",
      "comp_score = 0.9196846112576488, mean_score = 0.6107592581974552,\n"
     ]
    }
   ],
   "source": [
    "kfold = sklearn.model_selection.KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "score_means = []\n",
    "score_maxs = []\n",
    "for fold, (tr_idx, va_idx) in enumerate(kfold.split(df)):\n",
    "    train_dataset = TileDataset(df.iloc[tr_idx])\n",
    "    val_dataset = TileDataset(df.iloc[va_idx])\n",
    "    model = SimpleModel(\n",
    "        hidden_channels=[32, 48, 64, 84],\n",
    "        embedding_dim=32,\n",
    "        graph_in=64,\n",
    "        graph_out=64,\n",
    "        hidden_dim=128,\n",
    "        activation_fn=nn.ReLU,\n",
    "        dropout=0.2,\n",
    "    ).to(device)\n",
    "    criterion = CustomWeightedMSELoss()\n",
    "    epochs = 15\n",
    "    steps = len(train_dataset) * epochs\n",
    "    warmup_steps = int(steps * 0.15)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    scheduler = CosineLRScheduler(\n",
    "        optimizer,\n",
    "        t_initial=steps,\n",
    "        warmup_t=warmup_steps,\n",
    "        warmup_lr_init=1e-6,\n",
    "        lr_min=2e-8,\n",
    "    )\n",
    "\n",
    "    best_score = 0\n",
    "    best_score_max = 0\n",
    "    for epoch in range(15):\n",
    "        model.train()\n",
    "        pbar = tqdm(range(len(train_dataset)), leave=False)\n",
    "        loss_sum = 0\n",
    "        n = 0\n",
    "        for i in pbar:\n",
    "            cfg_ft, nd_ft, nd_op, ind, target = train_dataset[i]\n",
    "            cfg_ft, nd_ft, nd_op, ind, target = (\n",
    "                cfg_ft.to(device),\n",
    "                nd_ft.to(device),\n",
    "                nd_op.to(device),\n",
    "                ind.to(device),\n",
    "                target.to(device),\n",
    "            )\n",
    "\n",
    "            out = model(cfg_ft, nd_ft, nd_op, ind)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1e-2)\n",
    "            scheduler.step(i + len(train_dataset) * epoch)\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "            n += 1\n",
    "            pbar.set_description(\n",
    "                f\"running loss: {(loss_sum/n):.2f},current loss: {(loss.item()):.2f}\"\n",
    "            )\n",
    "        pbar.close()\n",
    "        model.eval()\n",
    "\n",
    "        tile_xla_predictions = []\n",
    "        pbar = tqdm(range(len(val_dataset)), leave=False)\n",
    "        for i in pbar:\n",
    "            cfg_ft, nd_ft, nd_op, ind, target = val_dataset[i]\n",
    "            cfg_ft, nd_ft, nd_op, ind, target = (\n",
    "                cfg_ft.to(device),\n",
    "                nd_ft.to(device),\n",
    "                nd_op.to(device),\n",
    "                ind.to(device),\n",
    "                target.to(device),\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                out = model(cfg_ft, nd_ft, nd_op, ind)\n",
    "            tile_xla_predictions.append(np.argsort(out.detach().cpu().numpy())[:50])\n",
    "        pbar.close()\n",
    "        score_mean = score_tile_mean(tile_xla_predictions, val_dataset.df)\n",
    "        score_max = score_tile_max(tile_xla_predictions, val_dataset.df)\n",
    "        print(\n",
    "            f\"fold {fold} epoch {epoch}, comp_score = {score_max:.3f}, mean_score = {score_mean:.3f},\"\n",
    "        )\n",
    "        if score_mean > best_score:\n",
    "            best_score = score_mean\n",
    "            best_score_max = score_max\n",
    "            torch.save(model.state_dict(), f\"best_model_{fold}.pth\")\n",
    "    score_means.append(best_score)\n",
    "    score_maxs.append(best_score_max)\n",
    "print(f\"comp_score = {np.mean(score_maxs)}, mean_score = {np.mean(score_means)},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 438.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 524.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 535.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 522.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 507.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 514.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 526.96it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 517.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 514.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:01<00:00, 505.30it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TileDataset(tile_xla[\"test\"])\n",
    "tile_xla_predictions = [[] for i in range(len(dataset))]\n",
    "for fold in range(10):\n",
    "    model.load_state_dict(torch.load(f\"best_model_{fold}.pth\"))\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(len(dataset)))\n",
    "    for i in pbar:\n",
    "        cfg_ft, nd_ft, nd_op, ind, target = dataset[i]\n",
    "        cfg_ft, nd_ft, nd_op, ind, target = (\n",
    "            cfg_ft.to(device),\n",
    "            nd_ft.to(device),\n",
    "            nd_op.to(device),\n",
    "            ind.to(device),\n",
    "            target.to(device),\n",
    "        )\n",
    "\n",
    "        out = model(cfg_ft, nd_ft, nd_op, ind)\n",
    "        tile_xla_predictions[i].append(out.detach().cpu().numpy())\n",
    "tile_xla_predictions = [\n",
    "    np.argsort(np.mean(pred, axis=0))[:5] for pred in tile_xla_predictions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TopConfigs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile:xla:d6f5f54247bd1e58a10b9e7062c636ab</td>\n",
       "      <td>0;22;21;20;19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tile:xla:e3a655daa38e34ec240df959b650ac16</td>\n",
       "      <td>513;1290;1282;866;697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tile:xla:f8c2c1a1098b2a361c26df668b286c87</td>\n",
       "      <td>41;116;101;202;166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile:xla:4dd1716853ed46ee4e7d09ede1732de8</td>\n",
       "      <td>6939;3321;1910;4644;7374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile:xla:d0a69155b6340748c36724e4bfc34be3</td>\n",
       "      <td>171;554;810;576;229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>layout:nlp:random:60880ed76de53f4d7a1b960b24f2...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>layout:nlp:random:23559853d9702baaaacbb0c83fd3...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>layout:nlp:random:f6c146fc5cf10be4f3accbaca989...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>layout:nlp:random:32531d07a084b319dce484f53a4c...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>layout:nlp:random:3a0c5517a87df8d82fd637b83298...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ID  \\\n",
       "0            tile:xla:d6f5f54247bd1e58a10b9e7062c636ab   \n",
       "1            tile:xla:e3a655daa38e34ec240df959b650ac16   \n",
       "2            tile:xla:f8c2c1a1098b2a361c26df668b286c87   \n",
       "3            tile:xla:4dd1716853ed46ee4e7d09ede1732de8   \n",
       "4            tile:xla:d0a69155b6340748c36724e4bfc34be3   \n",
       "..                                                 ...   \n",
       "889  layout:nlp:random:60880ed76de53f4d7a1b960b24f2...   \n",
       "890  layout:nlp:random:23559853d9702baaaacbb0c83fd3...   \n",
       "891  layout:nlp:random:f6c146fc5cf10be4f3accbaca989...   \n",
       "892  layout:nlp:random:32531d07a084b319dce484f53a4c...   \n",
       "893  layout:nlp:random:3a0c5517a87df8d82fd637b83298...   \n",
       "\n",
       "                                            TopConfigs  \n",
       "0                                        0;22;21;20;19  \n",
       "1                                513;1290;1282;866;697  \n",
       "2                                   41;116;101;202;166  \n",
       "3                             6939;3321;1910;4644;7374  \n",
       "4                                  171;554;810;576;229  \n",
       "..                                                 ...  \n",
       "889  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "890  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "891  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "892  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "893  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "\n",
       "[894 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./data/tpugraphs/sample_submission.csv\")\n",
    "for i, filename in enumerate(tile_xla[\"test\"][\"file\"].values):\n",
    "    id = \"tile:xla:\" + filename[:-4]\n",
    "    sub.loc[sub.ID == id, \"TopConfigs\"] = \";\".join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 231.48,current loss: 52.64:   0%|                 | 3/5709 [00:00<03:11, 29.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, comp_score = 0.448, mean_score = 0.192,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, comp_score = 0.979, mean_score = -0.967,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, comp_score = 0.974, mean_score = 0.334,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, comp_score = 0.972, mean_score = 0.289,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, comp_score = 0.908, mean_score = 0.268,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, comp_score = 0.943, mean_score = 0.329,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, comp_score = 0.960, mean_score = 0.382,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, comp_score = 0.967, mean_score = 0.385,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, comp_score = 0.958, mean_score = 0.350,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, comp_score = 0.927, mean_score = 0.448,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, comp_score = 0.938, mean_score = 0.326,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, comp_score = 0.948, mean_score = 0.508,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, comp_score = 0.969, mean_score = 0.399,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, comp_score = 0.965, mean_score = 0.455,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, comp_score = 0.945, mean_score = 0.485,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, comp_score = 0.949, mean_score = 0.467,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, comp_score = 0.948, mean_score = 0.476,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, comp_score = 0.937, mean_score = 0.532,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, comp_score = 0.959, mean_score = 0.549,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, comp_score = 0.946, mean_score = 0.565,\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    pbar = tqdm(range(len(train_dataset)), leave=False)\n",
    "    loss_sum = 0\n",
    "    n = 0\n",
    "    for i in pbar:\n",
    "        cfg_ft, nd_ft, nd_op, ind, target = train_dataset[i]\n",
    "        cfg_ft, nd_ft, nd_op, ind, target = (\n",
    "            cfg_ft.to(device),\n",
    "            nd_ft.to(device),\n",
    "            nd_op.to(device),\n",
    "            ind.to(device),\n",
    "            target.to(device),\n",
    "        )\n",
    "        out = model(cfg_ft, nd_ft, nd_op, ind)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1e-2)\n",
    "        scheduler.step(i + len(train_dataset) * epoch)\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        n += 1\n",
    "        pbar.set_description(\n",
    "            f\"running loss: {(loss_sum/n):.2f},current loss: {(loss.item()):.2f}\"\n",
    "        )\n",
    "    pbar.close()\n",
    "    model.eval()\n",
    "    tile_xla_predictions = []\n",
    "    pbar = tqdm(range(len(val_dataset)), leave=False)\n",
    "    for i in pbar:\n",
    "        cfg_ft, nd_ft, nd_op, ind, target = val_dataset[i]\n",
    "        cfg_ft, nd_ft, nd_op, ind, target = (\n",
    "            cfg_ft.to(device),\n",
    "            nd_ft.to(device),\n",
    "            nd_op.to(device),\n",
    "            ind.to(device),\n",
    "            target.to(device),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            out = model(cfg_ft, nd_ft, nd_op, ind)\n",
    "        tile_xla_predictions.append(np.argsort(out.detach().cpu().numpy())[:50])\n",
    "    pbar.close()\n",
    "    score_mean = score_tile_mean(tile_xla_predictions, val_dataset.df)\n",
    "    score_max = score_tile_max(tile_xla_predictions, val_dataset.df)\n",
    "    print(\n",
    "        f\"epoch {epoch}, comp_score = {score_max:.3f}, mean_score = {score_mean:.3f},\"\n",
    "    )\n",
    "    if score_mean > best_score:\n",
    "        best_score = score_mean\n",
    "        best_score_max = score_max\n",
    "        torch.save(model.state_dict(), f\"best_model.pth\")\n",
    "        print(\" * [@%i] Validation (NEW BEST): %s\" % (epoch + 1, str(best_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 844/844 [00:03<00:00, 256.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([   0, 5234, 4093, 3570, 3560]),\n",
       " array([291, 328, 521, 134, 327]),\n",
       " array([ 216,  958,  268,  425, 1007]),\n",
       " array([ 672,  198,   31, 1099,  978]),\n",
       " array([532, 435, 436, 456, 458]),\n",
       " array([66, 61, 18, 58,  7]),\n",
       " array([2631, 1621, 1620, 7916, 4079]),\n",
       " array([1251, 3192, 2150, 2801,  865]),\n",
       " array([ 393, 1209,  228,  234,  901]),\n",
       " array([241,  60, 219,  93,  72]),\n",
       " array([2306, 3286, 4163, 7846, 2855]),\n",
       " array([ 968,  226, 1293,  224,  567]),\n",
       " array([5340, 5659, 5663, 8188, 9199]),\n",
       " array([7764, 8034, 1619, 2609, 5195]),\n",
       " array([115, 128,  36,   1,  98]),\n",
       " array([749, 117, 333, 502, 725]),\n",
       " array([145, 355, 233, 352, 240]),\n",
       " array([ 657, 2192, 1836,  183, 1157]),\n",
       " array([   0, 3410, 3403, 3400, 3395]),\n",
       " array([ 805,  205,  332,  547, 1207]),\n",
       " array([428,  79, 794, 545, 968]),\n",
       " array([51, 43, 38, 35, 28]),\n",
       " array([ 245,  271,  689,  269, 1063]),\n",
       " array([209, 293, 621, 284, 283]),\n",
       " array([451, 112, 268, 538, 632]),\n",
       " array([ 0, 98, 97, 95, 94]),\n",
       " array([2286, 9697, 6940, 5381, 1186]),\n",
       " array([1, 4, 2, 7, 5]),\n",
       " array([8787, 2099, 6718, 6728, 6733]),\n",
       " array([ 638,  525, 1557,  526,  308]),\n",
       " array([ 517,  896,  209, 1155, 1265]),\n",
       " array([8787, 1266, 1263, 1261, 5382]),\n",
       " array([484, 397, 215, 655, 114]),\n",
       " array([4463, 2671, 2672, 2673, 2678]),\n",
       " array([ 0, 29, 28, 27, 26]),\n",
       " array([1281, 1023, 1022, 1020, 1014]),\n",
       " array([240, 589, 324, 321, 147]),\n",
       " array([37,  3, 41, 45, 26]),\n",
       " array([1466,  127, 2574, 2737, 2094]),\n",
       " array([234, 176, 158,  25, 120]),\n",
       " array([3, 4, 7, 6, 5]),\n",
       " array([2084, 4582, 3327, 4589, 1340]),\n",
       " array([ 15,  65, 110,  76,  17]),\n",
       " array([ 95,  27, 115, 118,  33]),\n",
       " array([ 652, 2527, 2526,  272, 2521]),\n",
       " array([2978, 1676, 1677, 1682, 1690]),\n",
       " array([1123, 1417,  391, 1410,   87]),\n",
       " array([453, 627, 250, 248, 244]),\n",
       " array([2590, 1951, 1959, 1963, 5532]),\n",
       " array([4266, 9150, 4062, 5427, 6080]),\n",
       " array([343, 116, 583, 746, 740]),\n",
       " array([4157, 3209, 2722,  741, 4749]),\n",
       " array([5790, 6535, 6536, 3734, 3729]),\n",
       " array([  0, 117, 118, 253, 120]),\n",
       " array([1323, 4203, 1205, 2961, 1201]),\n",
       " array([284, 260, 258, 245, 241]),\n",
       " array([ 466,  915, 1146, 1450,  515]),\n",
       " array([3033, 2762,  675, 2759, 5568]),\n",
       " array([305, 391,  87,  86, 393]),\n",
       " array([723, 571, 579, 838, 237]),\n",
       " array([183, 127, 138,  67,  46]),\n",
       " array([ 4,  5,  7, 11, 10]),\n",
       " array([412, 277, 276, 198,  41]),\n",
       " array([ 0, 20, 19, 18, 17]),\n",
       " array([2622, 4448, 4047, 2414, 1094]),\n",
       " array([2293,  350, 3357, 4919, 3877]),\n",
       " array([54, 36, 38, 39, 40]),\n",
       " array([383, 155,  26, 285, 184]),\n",
       " array([391, 189, 587, 424, 353]),\n",
       " array([29, 18,  8, 10,  1]),\n",
       " array([ 61, 136, 116,  38,  74]),\n",
       " array([ 0, 53, 46, 42, 39]),\n",
       " array([583, 719, 667, 189, 575]),\n",
       " array([20, 13, 95, 66, 33]),\n",
       " array([371, 304, 126, 303, 127]),\n",
       " array([  0, 865, 867, 869, 871]),\n",
       " array([1919, 1653, 5818, 4539,  317]),\n",
       " array([ 823, 2055, 2066, 1130,  441]),\n",
       " array([71, 25, 80, 54, 30]),\n",
       " array([1133,  281,  823,  279,  275]),\n",
       " array([  0, 140, 111, 163, 107]),\n",
       " array([287,  59, 367, 162, 333]),\n",
       " array([247, 342, 185, 180, 384]),\n",
       " array([28, 17,  5, 37, 25]),\n",
       " array([ 82,  24, 135, 134, 132]),\n",
       " array([535, 655, 160, 689, 956]),\n",
       " array([2, 1, 0]),\n",
       " array([24,  0, 23,  2, 22]),\n",
       " array([2468, 2824, 2841, 2851, 2880]),\n",
       " array([237, 432, 218, 293, 221]),\n",
       " array([  0, 272, 252, 239, 224]),\n",
       " array([3, 2, 1, 0, 5]),\n",
       " array([22,  9, 54, 67, 23]),\n",
       " array([2341, 5813, 6652, 3410, 2416]),\n",
       " array([1008,  241,  616,  617,  619]),\n",
       " array([271, 198,  69,  67, 375]),\n",
       " array([403, 410, 409, 396, 389]),\n",
       " array([ 855, 1980, 1364, 1983,  312]),\n",
       " array([   0, 2453, 2408, 2402, 2385]),\n",
       " array([1505, 1365,  695, 1102, 1367]),\n",
       " array([243,  98, 520, 383, 588]),\n",
       " array([414, 672, 221,  28, 724]),\n",
       " array([  0, 285, 282, 277, 276]),\n",
       " array([129,  87, 150, 128, 159]),\n",
       " array([ 940, 3481, 3478,  248, 3471]),\n",
       " array([130, 143, 146, 148, 149]),\n",
       " array([172,  32,  49, 261,  35]),\n",
       " array([ 233, 1989, 6381, 6402, 6404]),\n",
       " array([ 0, 51, 49, 48, 45]),\n",
       " array([8739, 8105, 4566, 1086, 4571]),\n",
       " array([ 158,  333,  311,  187, 1209]),\n",
       " array([252, 109, 111, 474, 888]),\n",
       " array([373, 123,  27, 387, 234]),\n",
       " array([ 64,  27, 386, 164, 278]),\n",
       " array([61, 11, 23, 68, 65]),\n",
       " array([1231,  593, 1430,  591, 1677]),\n",
       " array([347, 197, 821, 200, 201]),\n",
       " array([ 626,   16,  627, 1417,  562]),\n",
       " array([107, 121, 120, 116, 114]),\n",
       " array([265, 230, 240, 242, 255]),\n",
       " array([1213,  155, 1058,  266, 1056]),\n",
       " array([ 906, 1219,  847,  905,  325]),\n",
       " array([994, 535, 510, 103, 993]),\n",
       " array([9989,  698, 5560, 5533, 5527]),\n",
       " array([366, 157, 434, 162, 319]),\n",
       " array([ 91,  72,  48, 113,  47]),\n",
       " array([4001, 1278, 1287, 4158, 1290]),\n",
       " array([   0, 1229, 1209, 1208, 1192]),\n",
       " array([ 67, 360, 496, 364,  95]),\n",
       " array([1475,  207, 3840, 1226, 3662]),\n",
       " array([  0, 118, 115, 110, 107]),\n",
       " array([744, 592, 596, 638, 689]),\n",
       " array([ 491,  500, 2548,  978,  988]),\n",
       " array([  5, 179,  99,  70,  97]),\n",
       " array([ 95, 104, 110,  16,  26]),\n",
       " array([  0,  73,  72,  68, 394]),\n",
       " array([0, 1, 3, 2]),\n",
       " array([  0, 450, 451, 182,  90]),\n",
       " array([ 0, 21, 75, 24, 50]),\n",
       " array([2631, 2566, 1621, 2098, 1419]),\n",
       " array([ 495,  631, 1046,  603,  460]),\n",
       " array([ 347,  857,  865, 1248,  125]),\n",
       " array([296, 338, 178, 150, 695]),\n",
       " array([ 49,  21, 132,  40, 122]),\n",
       " array([ 29, 189, 204, 335, 176]),\n",
       " array([ 743,  527,   44, 1243,  184]),\n",
       " array([  0, 116, 114, 104, 102]),\n",
       " array([4863, 8064, 8062, 3460, 6009]),\n",
       " array([597, 734, 317, 741, 746]),\n",
       " array([3740, 2988, 2956, 2945, 2941]),\n",
       " array([276, 283,   7,  80, 169]),\n",
       " array([92, 29, 28, 77, 79]),\n",
       " array([ 91, 190,  10, 212, 103]),\n",
       " array([486, 556, 557, 558, 559]),\n",
       " array([682, 436, 435, 142, 429]),\n",
       " array([253,  56, 416, 288, 289]),\n",
       " array([297, 344, 853, 854, 334]),\n",
       " array([50, 43,  6, 42, 40]),\n",
       " array([24, 32, 19, 63, 33]),\n",
       " array([1672,  798,  795, 1218,  787]),\n",
       " array([629, 658, 657, 136, 126]),\n",
       " array([ 41,  36, 117,  27,  43]),\n",
       " array([196, 578, 567, 539, 537]),\n",
       " array([140,  15, 127, 121,  62]),\n",
       " array([ 441,  145,  565, 1251,  225]),\n",
       " array([3410, 3340, 3345, 3348, 3349]),\n",
       " array([1279,  722,  723, 6329,  725]),\n",
       " array([142, 585,  38, 653, 798]),\n",
       " array([ 0, 20, 19, 18, 17]),\n",
       " array([4837, 2875, 7524, 7735, 6569]),\n",
       " array([406,  13, 601, 623, 512]),\n",
       " array([94, 19, 41, 92, 45]),\n",
       " array([227, 258, 253, 475,  51]),\n",
       " array([4, 1, 0, 2, 5]),\n",
       " array([41, 32, 46, 35,  5]),\n",
       " array([646, 391,  76, 477, 478]),\n",
       " array([258,  75,  77,  80,  90]),\n",
       " array([ 451, 1524, 2305, 2306, 2307]),\n",
       " array([ 609,  831,  822,  154, 1172]),\n",
       " array([52, 80, 83, 84, 70]),\n",
       " array([2773,  689, 1131,  850, 3269]),\n",
       " array([3529, 1618, 1603, 5160, 2298]),\n",
       " array([1141,  690, 2464, 1553, 1416]),\n",
       " array([74, 15, 13, 61, 76]),\n",
       " array([502, 441, 620, 454,  41]),\n",
       " array([1671,  362, 7043, 1698, 6003]),\n",
       " array([0, 1]),\n",
       " array([27, 82, 44,  8, 50]),\n",
       " array([ 0, 25, 24, 23, 22]),\n",
       " array([529, 457, 580, 247, 250]),\n",
       " array([567, 221, 779, 917, 227]),\n",
       " array([ 8, 10,  7, 15,  4]),\n",
       " array([656, 122, 195, 416, 595]),\n",
       " array([9991, 6234, 1760, 6252, 6260]),\n",
       " array([2580, 7471, 5507, 5773,   95]),\n",
       " array([ 22,  21, 182,  58, 218]),\n",
       " array([7, 9, 6, 1, 5]),\n",
       " array([444, 117, 484, 114, 112]),\n",
       " array([522, 338, 335, 324, 320]),\n",
       " array([4998, 3737, 1544, 1543, 1540]),\n",
       " array([2533, 2809, 1482,  129,   98]),\n",
       " array([56,  0, 21, 19, 62]),\n",
       " array([ 0, 19,  3, 13, 23]),\n",
       " array([102,  95,  14,  12, 119]),\n",
       " array([1892, 1642,  562, 2850, 1640]),\n",
       " array([62, 56, 25, 78, 59]),\n",
       " array([544, 583, 302, 753, 608]),\n",
       " array([ 90, 111, 375, 272, 270]),\n",
       " array([1016,  617,  780,  321,  117]),\n",
       " array([  0, 429, 990, 166, 993]),\n",
       " array([888, 445, 412, 390,  50]),\n",
       " array([ 0, 72, 70, 69, 26]),\n",
       " array([137,  34,  29,  75,  79]),\n",
       " array([97,  2, 98, 50, 52]),\n",
       " array([ 0, 22, 21, 20, 19]),\n",
       " array([   0, 1920, 1912, 1910, 1908]),\n",
       " array([  0, 462, 460, 456, 452]),\n",
       " array([282, 725, 728, 729, 731]),\n",
       " array([4, 6, 7, 2, 3]),\n",
       " array([113,  40,  41,  49,  14]),\n",
       " array([  0, 573, 110, 548, 538]),\n",
       " array([ 3,  6, 14, 15, 35]),\n",
       " array([3373, 1065, 5257, 5255, 1225]),\n",
       " array([ 0, 25, 24, 23, 22]),\n",
       " array([281, 158, 143, 367, 142]),\n",
       " array([ 57, 399,  30, 151, 274]),\n",
       " array([2699, 2394, 2067,  138, 2392]),\n",
       " array([9987, 7635, 7630, 7622,  683]),\n",
       " array([ 633,  715, 2588, 1832, 1507]),\n",
       " array([18, 58, 94, 56, 55]),\n",
       " array([238, 291,  37, 450, 509]),\n",
       " array([  0, 158, 159, 160, 161]),\n",
       " array([5234, 8931, 4128, 6221, 1168]),\n",
       " array([62, 52, 51, 84, 49]),\n",
       " array([461,  15, 133,  24, 266]),\n",
       " array([84, 21, 46, 96, 14]),\n",
       " array([103,  68,  88,  36,  33]),\n",
       " array([4377, 1413,  287, 1015, 1040]),\n",
       " array([1352,  529, 1353, 1099, 1161]),\n",
       " array([717, 130, 145, 150, 663]),\n",
       " array([ 0, 29, 30, 31, 32]),\n",
       " array([1359,  238, 1127,  459, 1379]),\n",
       " array([138, 122, 153, 140,  92]),\n",
       " array([20, 18, 11, 19,  6]),\n",
       " array([21, 39, 37, 47, 32]),\n",
       " array([ 69, 485, 704, 486, 699]),\n",
       " array([30, 54,  2, 43, 35]),\n",
       " array([  0, 503, 491, 486, 457]),\n",
       " array([3, 1, 0, 2]),\n",
       " array([506,  26, 589,  49, 489]),\n",
       " array([1148,  768,  232,  231, 2153]),\n",
       " array([ 0, 60, 59, 58, 57]),\n",
       " array([89,  6, 27, 84, 79]),\n",
       " array([9160, 6869, 6871, 5040, 2197]),\n",
       " array([3, 1, 0, 2]),\n",
       " array([670, 450, 455, 456, 400]),\n",
       " array([2512, 1900, 1282, 2608, 2106]),\n",
       " array([630, 458, 657, 824, 820]),\n",
       " array([ 7,  9,  0,  1, 47]),\n",
       " array([7318, 2241, 7936, 5155, 5951]),\n",
       " array([ 54,  58,  68, 164,  52]),\n",
       " array([814, 759, 715, 685, 385]),\n",
       " array([4418, 4617, 4614, 1029, 1027]),\n",
       " array([2247, 2104, 2103, 2101, 2095]),\n",
       " array([4196, 4113, 6787, 1221, 1226]),\n",
       " array([530, 236, 508, 663, 220]),\n",
       " array([ 0, 30, 31, 32, 33]),\n",
       " array([107,  12,  27,  49,  66]),\n",
       " array([2034, 7525, 4307, 6305, 7976]),\n",
       " array([1507, 1497, 1252,  168,  165]),\n",
       " array([ 90, 202, 400,  25, 308]),\n",
       " array([139, 167, 543, 700, 699]),\n",
       " array([ 94, 186,  97,  71,  38]),\n",
       " array([  0, 890, 267, 266, 892]),\n",
       " array([27, 23, 30, 21, 35]),\n",
       " array([7550, 1264, 3729, 6985, 3739]),\n",
       " array([ 182,  498, 1083,  228,  775]),\n",
       " array([322, 229, 391, 375, 142]),\n",
       " array([111,  27,  89,  58,  80]),\n",
       " array([ 188, 1386,  712,  956,  376]),\n",
       " array([0, 2, 3, 1]),\n",
       " array([241,  55, 242, 235, 220]),\n",
       " array([7172,  964, 2688, 8696, 6651]),\n",
       " array([174,  36,  42,  57,  58]),\n",
       " array([  0, 326, 325, 309, 304]),\n",
       " array([0, 4, 2, 1, 3]),\n",
       " array([802, 140, 637, 441, 649]),\n",
       " array([126,  63,  77,  80,  20]),\n",
       " array([482, 119, 495, 117, 707]),\n",
       " array([3403, 2873, 3747, 3680, 1209]),\n",
       " array([  0,  33, 397,  37,  41]),\n",
       " array([3174, 2407, 2430, 2449, 2455]),\n",
       " array([2887, 5956, 5958, 4621, 3335]),\n",
       " array([  0, 681, 682, 684, 685]),\n",
       " array([26, 68, 38,  7, 36]),\n",
       " array([574, 283, 713, 280, 716]),\n",
       " array([9983, 4379, 7430, 9169, 9172]),\n",
       " array([453, 496, 495, 492, 488]),\n",
       " array([347, 344, 325, 192,  87]),\n",
       " array([673, 248, 951, 254, 945]),\n",
       " array([210, 134, 634, 855, 856]),\n",
       " array([1, 2, 5, 0, 6]),\n",
       " array([ 99,  76, 110,  28,  27]),\n",
       " array([599, 352, 369, 382, 418]),\n",
       " array([193, 498, 363, 310, 136]),\n",
       " array([4362, 4742, 1817, 2225, 4459]),\n",
       " array([7825, 3499, 3506, 1177, 7341]),\n",
       " array([16,  6,  5,  2,  3]),\n",
       " array([5532,  645, 3209,  647, 3204]),\n",
       " array([30, 23, 27, 61, 88]),\n",
       " array([  0, 327, 326, 325, 324]),\n",
       " array([ 513,  655,  880, 1299,  201]),\n",
       " array([425, 671, 511, 506,  63]),\n",
       " array([ 0, 45, 50, 20, 62]),\n",
       " array([ 93, 204, 292, 124, 339]),\n",
       " array([  0, 141, 142, 143, 145]),\n",
       " array([ 0, 96, 97, 98, 99]),\n",
       " array([ 60, 537, 543, 558, 631]),\n",
       " array([772, 479, 128, 474, 131]),\n",
       " array([1229,  307,  306,  845,  846]),\n",
       " array([ 0, 53, 28, 29, 30]),\n",
       " array([ 9,  1, 11,  6, 32]),\n",
       " array([27, 30, 65, 20, 57]),\n",
       " array([50, 31, 32, 51, 52]),\n",
       " array([264, 145, 334, 327, 321]),\n",
       " array([240, 734, 236, 238, 732]),\n",
       " array([5, 4, 0, 2, 1]),\n",
       " array([56, 91, 75, 58, 53]),\n",
       " array([   0, 1595, 1592, 1591, 1590]),\n",
       " array([580, 385, 411, 349, 281]),\n",
       " array([ 2, 60, 26,  8, 54]),\n",
       " array([46, 69, 23, 82, 61]),\n",
       " array([46, 34, 35, 38, 39]),\n",
       " array([495, 202, 212, 100, 432]),\n",
       " array([ 42, 150,  29, 137, 123]),\n",
       " array([497, 777, 778, 779, 317]),\n",
       " array([148,  72,  68,  22,   6]),\n",
       " array([4393, 3567, 3552, 3547, 3545]),\n",
       " array([4277, 9093, 2454, 4421, 5554]),\n",
       " array([137,  77, 106, 134, 126]),\n",
       " array([ 6, 10, 20,  9,  3]),\n",
       " array([721, 127, 125, 611, 612]),\n",
       " array([2271, 8309, 8310, 1368, 8314]),\n",
       " array([ 277, 1105,  770,  401,  642]),\n",
       " array([177,  52,  51, 131,  53]),\n",
       " array([517, 632, 415, 249, 397]),\n",
       " array([995, 228, 425, 426, 770]),\n",
       " array([21, 16, 30, 41, 83]),\n",
       " array([5577, 4774, 7411, 7410, 4775]),\n",
       " array([110,  24,  36,  50,   0]),\n",
       " array([ 0, 27, 26, 25, 24]),\n",
       " array([0, 1, 2, 3, 4]),\n",
       " array([265, 464, 462, 297, 190]),\n",
       " array([ 503,  131, 1131,  469,  137]),\n",
       " array([309,  97, 100, 155, 278]),\n",
       " array([  0, 281, 265, 236, 226]),\n",
       " array([5, 3, 2, 4, 0]),\n",
       " array([139,   5, 105, 130,  38]),\n",
       " array([5, 3, 2, 0, 4]),\n",
       " array([75, 21, 31, 12, 55]),\n",
       " array([107, 112, 174,  92, 139]),\n",
       " array([23, 20, 16, 28,  2]),\n",
       " array([175,  21,  80, 225, 136]),\n",
       " array([783, 276, 442, 112, 581]),\n",
       " array([ 0, 28, 29, 30, 31]),\n",
       " array([711, 397,  34, 508, 197]),\n",
       " array([  9,  43, 153, 146, 109]),\n",
       " array([  0, 233, 234, 149,  70]),\n",
       " array([525, 333, 664, 311, 294]),\n",
       " array([581, 631,  81,  36, 403]),\n",
       " array([10, 18,  6, 15, 19]),\n",
       " array([266, 271, 148, 265, 257]),\n",
       " array([544,  84, 337,  82,  81]),\n",
       " array([ 814,  660,  165,  946, 1394]),\n",
       " array([ 1,  3, 19, 15, 24]),\n",
       " array([ 836,  858,  850, 1671,  834]),\n",
       " array([  0, 234, 236, 237, 238]),\n",
       " array([ 0,  9,  8, 17,  2]),\n",
       " array([28, 32, 31, 11, 17]),\n",
       " array([ 60,  76, 264, 268, 269]),\n",
       " array([2, 1, 0]),\n",
       " array([6823, 3063, 1507, 1976, 7900]),\n",
       " array([160, 104, 101,  95,  94]),\n",
       " array([778, 491, 490, 482, 478]),\n",
       " array([ 628,  500, 1738,  555,  761]),\n",
       " array([2082, 7789, 5920, 2113, 5909]),\n",
       " array([185, 822, 823, 826, 223]),\n",
       " array([21, 31, 67, 40, 22]),\n",
       " array([ 410, 1121, 1572,  230, 1924]),\n",
       " array([ 69, 129,  84,  18, 115]),\n",
       " array([ 93,  64, 161,  83,  38]),\n",
       " array([19, 28, 14, 30, 11]),\n",
       " array([4081, 3575,  705, 3570, 3524]),\n",
       " array([11, 20,  2, 18,  4]),\n",
       " array([33,  1,  2, 28,  4]),\n",
       " array([535, 171, 291, 363, 504]),\n",
       " array([   0, 1514,  574, 1512, 1505]),\n",
       " array([17,  1, 18, 25, 12]),\n",
       " array([2279, 2564, 2565, 2567, 2568]),\n",
       " array([1283, 1232,  784,  117,  794]),\n",
       " array([ 553,  580,  725, 1743,  158]),\n",
       " array([ 370,  460, 1048, 1541, 1074]),\n",
       " array([ 79,  34,   8,  69, 129]),\n",
       " array([ 103,  932,  934,   34, 1472]),\n",
       " array([575, 159, 604, 605, 150]),\n",
       " array([ 872, 4213,  619, 5034, 6186]),\n",
       " array([435, 604, 607, 881, 879]),\n",
       " array([ 0,  1,  2, 18, 17]),\n",
       " array([163,  19, 186,  73, 248]),\n",
       " array([473, 480, 476, 471, 470]),\n",
       " array([1183,   73, 1586, 2890, 1060]),\n",
       " array([880, 896, 460, 902, 906]),\n",
       " array([  50,  941, 1842, 1489, 1721]),\n",
       " array([   0,  572,  574,  575, 1207]),\n",
       " array([  67,  185, 1235,  636,  633]),\n",
       " array([   0, 1124, 1125, 1126, 1130]),\n",
       " array([ 419, 1496, 1672,  239,  453]),\n",
       " array([  0, 344, 342, 341, 340]),\n",
       " array([597, 206, 484, 719, 215]),\n",
       " array([429, 863,  94, 333, 339]),\n",
       " array([146, 148,   5,  96,   1]),\n",
       " array([ 71, 257,  96,  92, 270]),\n",
       " array([2, 3, 1, 0, 4]),\n",
       " array([1134,  778,  779,  395,  149]),\n",
       " array([5, 1, 3, 4, 2]),\n",
       " array([18, 15,  7, 25,  6]),\n",
       " array([ 46,  52, 116,  75,   6]),\n",
       " array([931, 694, 420, 328, 156]),\n",
       " array([1136,  729,  267,  687,  613]),\n",
       " array([ 198,  221, 1271, 1468,   42]),\n",
       " array([414, 488, 332, 574, 632]),\n",
       " array([ 97, 532, 277, 122, 289]),\n",
       " array([53,  3, 49, 22, 52]),\n",
       " array([   0,  461,  462,  463, 1213]),\n",
       " array([346, 825, 204, 700, 564]),\n",
       " array([308,  68, 615, 443, 586]),\n",
       " array([1441, 8194, 4948, 3012, 5089]),\n",
       " array([   0, 3232, 3217, 3199, 3194]),\n",
       " array([ 230,  347,  993, 1881, 1654]),\n",
       " array([161, 144,  35, 146, 103]),\n",
       " array([107, 193, 114, 109, 213]),\n",
       " array([40, 68, 46, 29, 54]),\n",
       " array([43, 87, 30, 60, 85]),\n",
       " array([  0, 125,  31,  32, 430]),\n",
       " array([66, 26,  1, 30, 80]),\n",
       " array([2, 0, 5, 3, 4]),\n",
       " array([461, 542, 544, 545, 550]),\n",
       " array([54, 84, 82, 77, 17]),\n",
       " array([1576,  724, 7290, 3801, 3800]),\n",
       " array([556, 671, 676, 679, 226]),\n",
       " array([228, 248,  41, 247, 241]),\n",
       " array([220, 495, 476, 579, 475]),\n",
       " array([ 51,  65, 133,  35, 132]),\n",
       " array([   0,  558,  559, 1322,  569]),\n",
       " array([1639, 7286, 5102, 5367, 1222]),\n",
       " array([1794,  804,  100,   97, 1115]),\n",
       " array([  0, 192, 188, 179, 172]),\n",
       " array([879, 540, 546, 558, 111]),\n",
       " array([1038, 1086,  864,  745,  102]),\n",
       " array([812, 430, 437, 157, 474]),\n",
       " array([53, 87, 34, 35, 38]),\n",
       " array([1, 2, 4, 5, 6]),\n",
       " array([  0, 219, 906, 224, 225]),\n",
       " array([2729, 3238, 1932, 3753, 3746]),\n",
       " array([5, 3, 6, 2, 0]),\n",
       " array([5277, 5364, 8001, 3087, 2075]),\n",
       " array([82, 53, 55, 60, 67]),\n",
       " array([1956,  664, 2105, 2104, 2096]),\n",
       " array([  81,  168, 1389, 1369, 1310]),\n",
       " array([150,  73, 121,   3,  83]),\n",
       " array([39, 14, 57, 55, 53]),\n",
       " array([411, 414, 402, 398, 397]),\n",
       " array([3268, 3271, 4898, 5364, 1843]),\n",
       " array([ 0, 26, 53, 28, 29]),\n",
       " array([ 84, 250, 221, 149, 139]),\n",
       " array([207, 291,  79, 548, 531]),\n",
       " array([1, 2, 0, 3]),\n",
       " array([ 6, 18, 47, 37, 29]),\n",
       " array([   0, 2431, 2434, 2437, 2439]),\n",
       " array([556,  45, 336, 534, 569]),\n",
       " array([1, 2, 3, 6, 8]),\n",
       " array([550, 593, 673, 586, 583]),\n",
       " array([ 54,  49, 266, 140,  51]),\n",
       " array([58, 64, 69, 51, 75]),\n",
       " array([ 543, 1095, 1174,  221,   60]),\n",
       " array([ 29, 101,  81,  93,  92]),\n",
       " array([ 0, 21, 18, 17, 14]),\n",
       " array([469, 523, 515, 513, 510]),\n",
       " array([4, 5, 7, 1, 2]),\n",
       " array([ 74,  28,  29, 126, 122]),\n",
       " array([587, 621, 622, 627, 632]),\n",
       " array([459, 181,  92,  91,  90]),\n",
       " array([448, 582, 579, 568, 563]),\n",
       " array([19, 49,  3, 27,  6]),\n",
       " array([4994, 2242, 7935, 2240, 2239]),\n",
       " array([537, 506, 476, 599, 390]),\n",
       " array([5, 0, 3, 1, 4]),\n",
       " array([3, 0, 5, 1, 4]),\n",
       " array([1077,  559, 2002,  561, 2000]),\n",
       " array([   0, 1820, 1813,  596,  598]),\n",
       " array([ 93,  75,   6, 120,  17]),\n",
       " array([1456, 6514,  328, 5536, 1696]),\n",
       " array([ 50, 190, 151, 254, 216]),\n",
       " array([ 94, 144, 101, 104,  23]),\n",
       " array([  0, 446, 448, 455, 471]),\n",
       " array([200, 216, 214, 211, 209]),\n",
       " array([7, 0, 5, 6, 3]),\n",
       " array([ 832,  155, 1320, 1072,  218]),\n",
       " array([ 921,  163, 1368,  305, 1301]),\n",
       " array([213,  54, 473, 395, 387]),\n",
       " array([ 0, 95, 94, 90, 87]),\n",
       " array([51, 39,  5, 35,  7]),\n",
       " array([244, 290,  76, 442, 144]),\n",
       " array([115, 102,  43,  42,  57]),\n",
       " array([1239,  873,  876,  877,  328]),\n",
       " array([155, 553, 592, 430, 872]),\n",
       " array([84, 41, 22, 72, 74]),\n",
       " array([2, 1, 3, 0]),\n",
       " array([ 30, 114, 109, 113, 137]),\n",
       " array([1747,  343,  527,  620,  958]),\n",
       " array([195, 175,  24, 230,  85]),\n",
       " array([ 76,  78,  74,  73, 117]),\n",
       " array([1553, 1134, 1135,  374, 1137]),\n",
       " array([1, 3, 4, 2, 0]),\n",
       " array([  0, 227, 200, 182, 181]),\n",
       " array([57, 75, 72, 71, 69]),\n",
       " array([ 90,  22,  51, 125,  25]),\n",
       " array([ 57, 168, 170, 124, 178]),\n",
       " array([260, 337, 333, 325, 318]),\n",
       " array([77, 81, 91, 87, 84]),\n",
       " array([15,  0, 92, 90, 85]),\n",
       " array([29, 13, 26, 17,  3]),\n",
       " array([530, 399, 404, 276, 412]),\n",
       " array([71, 36, 32, 74, 62]),\n",
       " array([  0,  30, 129,  65, 121]),\n",
       " array([1383, 1069, 1013, 1302,  312]),\n",
       " array([24,  8, 21,  6,  3]),\n",
       " array([  0, 446, 447, 450, 229]),\n",
       " array([132,   9,  27,  29,  36]),\n",
       " array([ 0,  1,  2,  3, 19]),\n",
       " array([12, 40,  9, 54, 14]),\n",
       " array([122,   3,  71, 110, 123]),\n",
       " array([ 807,  499,  502, 1301,  505]),\n",
       " array([ 94, 109, 108, 107,  40]),\n",
       " array([ 0, 29, 30, 31, 32]),\n",
       " array([3481,  702,  696, 1641, 3867]),\n",
       " array([3725, 1062, 6646, 3878, 1057]),\n",
       " array([2676, 1729,  710, 1712, 1863]),\n",
       " array([ 56, 268,  69,  73, 246]),\n",
       " array([147, 109,  24, 102,  26]),\n",
       " array([ 0, 84, 81, 65, 60]),\n",
       " array([  0, 321, 320, 319, 318]),\n",
       " array([207, 521,  78, 316, 946]),\n",
       " array([1149,  694, 4410,  696,  697]),\n",
       " array([ 22,  10, 142, 185, 171]),\n",
       " array([140,  31,  30,  29,  28]),\n",
       " array([482,  78, 469, 369, 488]),\n",
       " array([0, 7, 5, 1, 3]),\n",
       " array([ 820, 2275, 2277, 2280, 1457]),\n",
       " array([ 0, 27, 20, 55, 36]),\n",
       " array([609,  89, 616, 641, 705]),\n",
       " array([ 701,  676,  686,  687, 1502]),\n",
       " array([454, 622, 627, 246, 519]),\n",
       " array([17, 40, 42, 30, 44]),\n",
       " array([8548, 6079, 8161, 5587, 1081]),\n",
       " array([27, 23, 28, 19, 14]),\n",
       " array([407, 186, 190, 193, 196]),\n",
       " array([5796, 7940, 7941, 7946, 5749]),\n",
       " array([10,  1, 40,  3, 41]),\n",
       " array([125,   9, 189,  24,  63]),\n",
       " array([ 820,  251,  402, 1327,  815]),\n",
       " array([  0,  89,  88, 143,  85]),\n",
       " array([ 968, 2034, 2030,  367, 2019]),\n",
       " array([1071,  612,  151, 1017, 1025]),\n",
       " array([ 900,  669, 1064, 1050, 1029]),\n",
       " array([488, 913, 934, 512, 537]),\n",
       " array([ 51,  98,  28,  27, 112]),\n",
       " array([0, 1, 3, 2, 4]),\n",
       " array([92, 57, 63, 67, 76]),\n",
       " array([  0,  50,  57, 177,  63]),\n",
       " array([3, 1, 4, 0, 5]),\n",
       " array([ 47,  22, 146, 155, 108]),\n",
       " array([3008, 4075, 4066, 7955,  900]),\n",
       " array([1, 0, 2]),\n",
       " array([3, 1, 2, 4, 0]),\n",
       " array([125, 118, 230, 108, 414]),\n",
       " array([  89, 1150,  719, 1153,  718]),\n",
       " array([ 0, 57, 55, 54, 51]),\n",
       " array([264, 273, 266, 258, 253]),\n",
       " array([43, 25,  0, 68, 52]),\n",
       " array([160, 375, 140, 551, 554]),\n",
       " array([1351, 7412,   77, 3387, 7223]),\n",
       " array([ 0, 98, 97, 96, 93]),\n",
       " array([  0,  24, 118, 117,  58]),\n",
       " array([0, 2, 1]),\n",
       " array([125, 658, 729, 727, 476]),\n",
       " array([221, 317,  11, 146, 155]),\n",
       " array([ 0, 22, 21, 20, 19]),\n",
       " array([157,  56, 116,  50,  20]),\n",
       " array([665, 926, 411, 924, 919]),\n",
       " array([ 27, 340, 241, 240, 239]),\n",
       " array([64, 38, 42, 46, 63]),\n",
       " array([ 27, 416, 476, 844, 452]),\n",
       " array([25, 49, 47, 39, 34]),\n",
       " array([820, 267, 210, 822, 697]),\n",
       " array([ 67, 207, 125, 289, 211]),\n",
       " array([2, 1, 0]),\n",
       " array([846, 603, 611, 618, 625]),\n",
       " array([ 694, 2195,  148, 1229, 1867]),\n",
       " array([  0,  72, 398, 653, 664]),\n",
       " array([0, 2, 1]),\n",
       " array([89, 50, 23, 81, 49]),\n",
       " array([166, 116, 233, 161, 119]),\n",
       " array([715, 679, 677, 675, 674]),\n",
       " array([  0, 135, 136, 137, 141]),\n",
       " array([  0, 636, 649, 657, 681]),\n",
       " array([6, 4, 1, 5, 3]),\n",
       " array([24, 16, 28, 10,  2]),\n",
       " array([5, 6, 0, 1, 2]),\n",
       " array([ 39,  20,  48,  18, 153]),\n",
       " array([88, 32, 59, 63, 64]),\n",
       " array([  0, 298, 286, 284, 283]),\n",
       " array([1882,  431, 1993, 1998, 2006]),\n",
       " array([691, 559, 168, 554, 551]),\n",
       " array([ 0, 29, 60, 31, 35]),\n",
       " array([  0, 727, 122, 125, 679]),\n",
       " array([ 8, 14,  7,  6,  4]),\n",
       " array([192, 193, 189, 187, 174]),\n",
       " array([8339, 8301, 8306, 8309, 1304]),\n",
       " array([16, 53,  1, 30, 52]),\n",
       " array([14, 11, 13, 51, 44]),\n",
       " array([391, 343, 402, 361,   5]),\n",
       " array([ 8, 27, 44,  5,  6]),\n",
       " array([1940,  792,  794,  796,  798]),\n",
       " array([378, 469, 461, 459,  56]),\n",
       " array([ 62,  85, 182,  91,  79]),\n",
       " array([813, 749, 830, 876, 823]),\n",
       " array([985, 699, 135, 142, 680]),\n",
       " array([435, 475, 473, 471, 470]),\n",
       " array([ 70, 124, 340, 339, 322]),\n",
       " array([7, 0, 2, 3, 4]),\n",
       " array([0, 2, 3, 4, 5]),\n",
       " array([645, 297, 505, 294, 293]),\n",
       " array([61, 42, 47, 10, 66]),\n",
       " array([15, 13,  1,  2,  4]),\n",
       " array([512, 217,  50, 218, 219]),\n",
       " array([1745, 2712, 1640,  760,   73]),\n",
       " array([  0,  95, 179,  90,  88]),\n",
       " array([818, 631, 654, 663, 676]),\n",
       " array([  0, 322, 321, 320, 319]),\n",
       " array([115, 343, 342, 147, 722]),\n",
       " array([575,  49, 610, 208,  53]),\n",
       " array([1114, 1873, 1570,   80, 1077]),\n",
       " array([22, 33, 10, 39, 42]),\n",
       " array([3712, 4005, 2062, 4592, 7613]),\n",
       " array([169, 132, 333, 265, 340]),\n",
       " array([34, 82, 27, 79, 31]),\n",
       " array([  0, 805, 206, 804, 801]),\n",
       " array([146, 151, 134, 133, 137]),\n",
       " array([  0, 292, 277, 256,  44]),\n",
       " array([184, 102, 169, 100,  99]),\n",
       " array([  0,  35,  36, 114, 112]),\n",
       " array([3, 4, 0, 2, 1]),\n",
       " array([56, 32, 22,  9, 42]),\n",
       " array([ 75,  37,  42, 116,  20]),\n",
       " array([74, 36, 61, 24, 21]),\n",
       " array([161, 118,  61, 112,  37]),\n",
       " array([34, 31,  4, 37, 16]),\n",
       " array([230, 365, 488, 126,  67]),\n",
       " array([ 603,  808,  103,  622, 1051]),\n",
       " array([ 75, 295, 620, 970, 576]),\n",
       " array([ 0, 29, 28, 27, 26]),\n",
       " array([29, 27, 84, 57, 30]),\n",
       " array([212, 259, 222,  34, 170]),\n",
       " array([0, 1]),\n",
       " array([1, 3, 2, 0, 5]),\n",
       " array([  0, 503, 501, 494, 492]),\n",
       " array([394, 329, 639, 358, 260]),\n",
       " array([1584, 1780,  570, 1185, 4926]),\n",
       " array([1072,  576,  566,  565,  554]),\n",
       " array([4847, 4344, 3547, 8088, 9335]),\n",
       " array([  0, 264, 655, 262, 261]),\n",
       " array([62, 66, 58, 55, 47]),\n",
       " array([75, 65, 52, 44, 70]),\n",
       " array([2704, 3606, 3549, 3529, 3507]),\n",
       " array([280, 284, 743, 744, 560]),\n",
       " array([128, 129,  74,  15,  98]),\n",
       " array([ 0, 19, 18, 17, 16]),\n",
       " array([637, 905, 818, 350, 866]),\n",
       " array([ 238, 2935,  695,  623, 3919]),\n",
       " array([622, 303, 539,  81, 192]),\n",
       " array([   0, 1192, 3003, 3004, 3026]),\n",
       " array([1029, 1034,  900,  119, 1016]),\n",
       " array([ 956, 1793,  854, 1487,   99]),\n",
       " array([ 357, 1745,  467,  910, 1434]),\n",
       " array([ 587, 1393,  181,  658, 1506]),\n",
       " array([ 0, 21, 20, 19, 18]),\n",
       " array([  97,  119, 1599,  432, 1048]),\n",
       " array([1585, 1713,  611, 2459,  423]),\n",
       " array([  0, 296, 295, 294, 293]),\n",
       " array([ 89,  29, 167,  16, 184]),\n",
       " array([ 0, 22, 21, 20, 19]),\n",
       " array([ 77, 702, 235, 781, 354]),\n",
       " array([29,  0, 33, 31, 28]),\n",
       " array([4278, 4010,  275, 1970, 1150]),\n",
       " array([7950, 5138, 5139, 5157, 2284]),\n",
       " array([ 621,  559, 1082,  557,  556]),\n",
       " array([2835, 5891, 4808,  746, 5662]),\n",
       " array([923, 870, 493, 308, 619]),\n",
       " array([ 0, 24, 28, 31, 33]),\n",
       " array([293, 182, 469, 426, 255]),\n",
       " array([   0, 1594, 1593, 1592, 1590]),\n",
       " array([427, 514, 513, 124, 125]),\n",
       " array([13,  6,  7,  0,  8]),\n",
       " array([1046,  315,  961,  452,  908]),\n",
       " array([68, 92, 59, 81, 99]),\n",
       " array([126, 131, 193,  85, 197]),\n",
       " array([ 1,  6, 14, 26, 25]),\n",
       " array([125,  37, 234, 172, 171]),\n",
       " array([ 0, 25, 27, 35, 38]),\n",
       " array([ 0, 29, 28, 27, 26]),\n",
       " array([54, 18, 32, 34, 26]),\n",
       " array([1001,  126, 1074, 1094, 1101]),\n",
       " array([ 908,  794, 1393,  153,  696]),\n",
       " array([397,  32, 306, 330,  35]),\n",
       " array([ 97, 170, 140, 122,  59]),\n",
       " array([110,  76,  69,  77,  68]),\n",
       " array([354, 554, 466,  17, 155]),\n",
       " array([3, 0, 1, 2, 4]),\n",
       " array([1947, 2145, 2451,  954, 3790]),\n",
       " array([1639,  438,  164, 2164, 2414]),\n",
       " array([1198,  673,  504,  247,  506]),\n",
       " array([101,  36,  94,   2, 112]),\n",
       " array([ 685,  959, 1216, 1323,  446]),\n",
       " array([1270,  653, 1008,  156,  726]),\n",
       " array([ 187, 2966, 2253, 4932, 3561]),\n",
       " array([4987, 3409, 8793, 3419, 3424]),\n",
       " array([314, 248, 251, 252, 256]),\n",
       " array([7487, 4316, 1309, 1318, 4301]),\n",
       " array([21, 11,  9,  1,  3]),\n",
       " array([ 0, 87, 27, 28, 85]),\n",
       " array([157,  68, 102, 147,  14]),\n",
       " array([202, 204, 314, 201, 326]),\n",
       " array([ 326,  878, 1353,  518,  104]),\n",
       " array([127, 561, 354, 566, 568]),\n",
       " array([1250, 1060,  963,  292,  776]),\n",
       " array([83,  2, 98, 96, 94]),\n",
       " array([ 749,  336,  303, 1037,  513]),\n",
       " array([ 982, 1193,  403, 2974, 1192]),\n",
       " array([ 3, 28, 24, 27,  2]),\n",
       " array([20, 16, 25, 34, 36]),\n",
       " array([2706, 4417, 1280, 8336, 9109]),\n",
       " array([1634, 2589, 2565,  417,  416]),\n",
       " array([3238, 2186, 1104, 8721,  314]),\n",
       " array([4499, 4807, 4817, 4854, 4866]),\n",
       " array([0, 1, 2]),\n",
       " array([ 229,  768,  520, 1327, 1442]),\n",
       " array([ 0, 22, 21, 20, 19]),\n",
       " array([61, 18, 39, 16, 14]),\n",
       " array([117,  26,  70,  73,  78]),\n",
       " array([761, 154, 396, 390, 158]),\n",
       " array([170, 571, 566, 563, 562]),\n",
       " array([ 276, 2979,  403, 6952, 1716]),\n",
       " array([410, 124, 233,  46, 402]),\n",
       " array([340, 433, 191, 186, 488]),\n",
       " array([1, 3, 0, 4, 2]),\n",
       " array([659, 557, 554,  43, 534]),\n",
       " array([ 0, 29, 30, 31, 32]),\n",
       " array([6168, 3022, 1972, 4696, 4459]),\n",
       " array([1443, 2325,  870,  877,  878]),\n",
       " array([ 587, 1045, 1359,  868, 1039]),\n",
       " array([2063, 1009, 5018, 5048, 1003]),\n",
       " array([ 401, 1274,  950, 1868,  309]),\n",
       " array([118,  35,  78,  44, 127]),\n",
       " array([185,  70, 261, 123, 164]),\n",
       " array([0, 2, 5, 4, 1]),\n",
       " array([350, 519, 259, 129, 407]),\n",
       " array([2513, 6746,  627, 5060, 9906]),\n",
       " array([   0, 4143, 4141, 4140, 4125]),\n",
       " array([345, 426,  57, 173, 188]),\n",
       " array([170,  51,  40,  38, 193]),\n",
       " array([3793, 2381, 2373, 2364, 2362]),\n",
       " array([4, 2, 6, 0, 3]),\n",
       " array([487, 488, 567, 127, 560]),\n",
       " array([77, 25, 61, 27, 60]),\n",
       " array([ 826,  536, 1352, 1358,  525]),\n",
       " array([15, 74, 37, 36, 55]),\n",
       " array([6, 2, 4, 5, 0]),\n",
       " array([266, 156,  68, 335, 161]),\n",
       " array([1931, 2418, 1342, 4889, 4556]),\n",
       " array([145, 363, 366, 180,  28]),\n",
       " array([ 3,  8, 11, 13, 10]),\n",
       " array([512, 226, 230, 240, 251]),\n",
       " array([ 31, 618, 561, 621, 526]),\n",
       " array([55, 42, 97, 32,  1]),\n",
       " array([4393,  724, 7799, 6078,  727]),\n",
       " array([2, 0, 1]),\n",
       " array([982, 485, 835, 926, 148]),\n",
       " array([472, 362, 373, 376, 394]),\n",
       " array([ 725, 1001, 1007, 1019, 1027]),\n",
       " array([567, 581, 301, 509, 216]),\n",
       " array([530, 469, 489, 105, 491]),\n",
       " array([251, 143, 365, 153, 155]),\n",
       " array([ 77, 169, 250, 102, 218]),\n",
       " array([36, 55,  1, 48,  0]),\n",
       " array([25, 18, 49, 76,  9]),\n",
       " array([13,  8,  0, 14, 25]),\n",
       " array([5, 4, 2, 0, 1]),\n",
       " array([  52, 1363, 1147, 1348,  642]),\n",
       " array([111,  70, 295, 423,  87]),\n",
       " array([ 15,  89,  38, 108,  41]),\n",
       " array([515, 422, 643, 302,  49]),\n",
       " array([ 41, 101, 116, 202, 166]),\n",
       " array([102, 319, 144, 321,  33]),\n",
       " array([4992, 6748, 6755, 1930, 1925]),\n",
       " array([46, 64, 22, 63, 62]),\n",
       " array([7123, 1006, 4755, 1978, 6638]),\n",
       " array([ 0, 26, 27, 28, 29]),\n",
       " array([121, 131, 150, 221, 137]),\n",
       " array([491, 141, 134, 425, 546]),\n",
       " array([2315,  406, 3600, 3602, 1761]),\n",
       " array([ 701, 1104, 1101,  697,  696]),\n",
       " array([572, 802, 796, 435, 786]),\n",
       " array([148, 104,  26,  99,  33]),\n",
       " array([63, 71, 58, 16, 61]),\n",
       " array([  0,  52, 100,  98,  29]),\n",
       " array([41,  3, 34, 39, 13]),\n",
       " array([1852, 1888, 1886, 1885, 1884]),\n",
       " array([366, 356, 789, 351, 348]),\n",
       " array([193, 102, 143,  54, 155]),\n",
       " array([1036, 1021, 1023, 1025, 1028]),\n",
       " array([ 95, 362, 836, 854, 856]),\n",
       " array([  0, 397, 421, 430,  95]),\n",
       " array([   0,  967, 3143,  986, 2689]),\n",
       " array([6551, 5928, 5927, 1221, 7527]),\n",
       " array([0, 3, 4, 1, 2]),\n",
       " array([33, 56, 60, 54, 10]),\n",
       " array([157, 101, 236,  23, 170]),\n",
       " array([  53, 1167, 3002, 2151, 2198]),\n",
       " array([7776, 1886, 1054, 7482, 1052]),\n",
       " array([232,  61,  71, 148, 203]),\n",
       " array([ 31, 119,  54, 135,  49]),\n",
       " array([ 842, 1280,  286, 1272, 1271]),\n",
       " array([75, 41, 52, 61, 63])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TileDataset(tile_xla[\"test\"])\n",
    "tile_xla_predictions = []\n",
    "model.load_state_dict(torch.load(f\"best_model.pth\"))\n",
    "model.eval()\n",
    "pbar = tqdm(range(len(dataset)))\n",
    "for i in pbar:\n",
    "    cfg_ft, nd_ft, nd_op, ind, target = dataset[i]\n",
    "    cfg_ft, nd_ft, nd_op, ind, target = (\n",
    "        cfg_ft.to(device),\n",
    "        nd_ft.to(device),\n",
    "        nd_op.to(device),\n",
    "        ind.to(device),\n",
    "        target.to(device),\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        out = model(cfg_ft, nd_ft, nd_op, ind)\n",
    "    tile_xla_predictions.append(np.argsort(out.detach().cpu().numpy())[:5])\n",
    "tile_xla_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TopConfigs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile:xla:d6f5f54247bd1e58a10b9e7062c636ab</td>\n",
       "      <td>0;22;21;20;19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tile:xla:e3a655daa38e34ec240df959b650ac16</td>\n",
       "      <td>1250;1060;963;292;776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tile:xla:f8c2c1a1098b2a361c26df668b286c87</td>\n",
       "      <td>41;101;116;202;166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile:xla:4dd1716853ed46ee4e7d09ede1732de8</td>\n",
       "      <td>7172;964;2688;8696;6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile:xla:d0a69155b6340748c36724e4bfc34be3</td>\n",
       "      <td>0;264;655;262;261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>layout:nlp:random:60880ed76de53f4d7a1b960b24f2...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>layout:nlp:random:23559853d9702baaaacbb0c83fd3...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>layout:nlp:random:f6c146fc5cf10be4f3accbaca989...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>layout:nlp:random:32531d07a084b319dce484f53a4c...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>layout:nlp:random:3a0c5517a87df8d82fd637b83298...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ID  \\\n",
       "0            tile:xla:d6f5f54247bd1e58a10b9e7062c636ab   \n",
       "1            tile:xla:e3a655daa38e34ec240df959b650ac16   \n",
       "2            tile:xla:f8c2c1a1098b2a361c26df668b286c87   \n",
       "3            tile:xla:4dd1716853ed46ee4e7d09ede1732de8   \n",
       "4            tile:xla:d0a69155b6340748c36724e4bfc34be3   \n",
       "..                                                 ...   \n",
       "889  layout:nlp:random:60880ed76de53f4d7a1b960b24f2...   \n",
       "890  layout:nlp:random:23559853d9702baaaacbb0c83fd3...   \n",
       "891  layout:nlp:random:f6c146fc5cf10be4f3accbaca989...   \n",
       "892  layout:nlp:random:32531d07a084b319dce484f53a4c...   \n",
       "893  layout:nlp:random:3a0c5517a87df8d82fd637b83298...   \n",
       "\n",
       "                                            TopConfigs  \n",
       "0                                        0;22;21;20;19  \n",
       "1                                1250;1060;963;292;776  \n",
       "2                                   41;101;116;202;166  \n",
       "3                              7172;964;2688;8696;6651  \n",
       "4                                    0;264;655;262;261  \n",
       "..                                                 ...  \n",
       "889  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "890  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "891  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "892  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "893  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "\n",
       "[894 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./data/tpugraphs/sample_submission.csv\")\n",
    "for i, filename in enumerate(tile_xla[\"test\"][\"file\"].values):\n",
    "    id = \"tile:xla:\" + filename[:-4]\n",
    "    sub.loc[sub.ID == id, \"TopConfigs\"] = \";\".join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, List, Union, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward\n",
    "from transformers.activations import ACT2FN\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GraphConfig:\n",
    "    num_hidden_layers: int = 8\n",
    "    embedding_size: int = 256\n",
    "    num_attention_heads: int = 16\n",
    "    intermediate_size: int = 64\n",
    "    chunk_size_feed_forward: int = 64\n",
    "    attention_probs_dropout_prob: float = 0.0\n",
    "    max_position_embeddings: int = 512\n",
    "    hidden_dropout_prob: float = 0.0\n",
    "    layer_norm_eps: float = 1e-12\n",
    "    hidden_act: torch.nn = torch.nn.GELU\n",
    "    initializer_range: float = 0.02\n",
    "    output_hidden_states: bool = False\n",
    "    output_attentions: bool = False\n",
    "    gradient_checkpointing: bool = False\n",
    "    margin: float = 0.1\n",
    "    number_permutations: int = 10\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.hidden_size = self.embedding_size + 140\n",
    "\n",
    "    def validate(self):\n",
    "        if self.hidden_size % self.num_attention_heads != 0 and not hasattr(\n",
    "            self, \"embedding_size\"\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({self.num_attention_heads})\"\n",
    "            )\n",
    "\n",
    "    def save_config(self, path):\n",
    "        config = asdict(self)\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load_config(cls, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_kwargs = dict(\n",
    "    embedding_size=128,\n",
    "    num_attention_heads=4,\n",
    "    num_hidden_layers=2,\n",
    "    intermediate_size=64,\n",
    "    gradient_checkpointing=True,\n",
    "    margin=0.1,\n",
    "    number_permutations=4,\n",
    ")\n",
    "\n",
    "config = GraphConfig(**config_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config: GraphConfig, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        config.validate()\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        self.position_embedding_type = position_embedding_type or getattr(\n",
    "            config, \"position_embedding_type\", \"absolute\"\n",
    "        )\n",
    "        if (\n",
    "            self.position_embedding_type == \"relative_key\"\n",
    "            or self.position_embedding_type == \"relative_key_query\"\n",
    "        ):\n",
    "            self.max_position_embeddings = config.max_position_embeddings\n",
    "            self.distance_embedding = nn.Embedding(\n",
    "                2 * config.max_position_embeddings - 1, self.attention_head_size\n",
    "            )\n",
    "\n",
    "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (\n",
    "            self.num_attention_heads,\n",
    "            self.attention_head_size,\n",
    "        )\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "        query_layer = self.transpose_for_scores(self.query(hidden_states))\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        if (\n",
    "            self.position_embedding_type == \"relative_key\"\n",
    "            or self.position_embedding_type == \"relative_key_query\"\n",
    "        ):\n",
    "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
    "            position_ids_l = torch.arange(\n",
    "                query_length, dtype=torch.long, device=hidden_states.device\n",
    "            ).view(-1, 1)\n",
    "            position_ids_r = torch.arange(\n",
    "                key_length, dtype=torch.long, device=hidden_states.device\n",
    "            ).view(1, -1)\n",
    "            distance = position_ids_l - position_ids_r\n",
    "\n",
    "            positional_embedding = self.distance_embedding(\n",
    "                distance + self.max_position_embeddings - 1\n",
    "            )\n",
    "            positional_embedding = positional_embedding.to(\n",
    "                dtype=query_layer.dtype\n",
    "            )  # fp16 compatibility\n",
    "\n",
    "            if self.position_embedding_type == \"relative_key\":\n",
    "                relative_position_scores = torch.einsum(\n",
    "                    \"bhld,lrd->bhlr\", query_layer, positional_embedding\n",
    "                )\n",
    "                attention_scores = attention_scores + relative_position_scores\n",
    "            elif self.position_embedding_type == \"relative_key_query\":\n",
    "                relative_position_scores_query = torch.einsum(\n",
    "                    \"bhld,lrd->bhlr\", query_layer, positional_embedding\n",
    "                )\n",
    "                relative_position_scores_key = torch.einsum(\n",
    "                    \"bhrd,lrd->bhlr\", key_layer, positional_embedding\n",
    "                )\n",
    "                attention_scores = (\n",
    "                    attention_scores\n",
    "                    + relative_position_scores_query\n",
    "                    + relative_position_scores_key\n",
    "                )\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(-1)\n",
    "            attention_mask = attention_mask.expand(-1, self.num_attention_heads, -1, -1)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = (\n",
    "                attention_probs * head_mask\n",
    "            )  # DONE: Same Head Mask for all Heads\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(new_context_layer_shape)\n",
    "\n",
    "        outputs = (\n",
    "            (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "        )\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_states: torch.Tensor, input_tensor: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config: GraphConfig, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(\n",
    "            config, position_embedding_type=position_embedding_type\n",
    "        )\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        self_outputs = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions,\n",
    "        )\n",
    "        attention_output = self.output(self_outputs[0], hidden_states)\n",
    "        outputs = (attention_output,) + self_outputs[\n",
    "            1:\n",
    "        ]  # add attention_probs if we output them\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config: GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn()(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config: GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_states: torch.Tensor, input_tensor: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(\n",
    "            hidden_states + input_tensor\n",
    "        )  # Residual Connection\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pytorch_utils import apply_chunking_to_forward\n",
    "\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config: GraphConfig):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "        outputs = self_attention_outputs[\n",
    "            1:\n",
    "        ]  # add self attentions if we output attention weights\n",
    "        layer_output = self.feed_forward_chunk(attention_output)\n",
    "        outputs = (layer_output,) + outputs\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config: GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList(\n",
    "            [BertLayer(config) for _ in range(config.num_hidden_layers)]\n",
    "        )\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[torch.Tensor, BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        for layer_module in self.layer:\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def custom_forward(module):\n",
    "                    return module(hidden_states, attention_mask, output_attentions)\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    custom_forward, layer_module\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "        pooled_output = hidden_states.mean(dim=1)\n",
    "\n",
    "        if return_dict:\n",
    "            return BaseModelOutputWithPastAndCrossAttentions(\n",
    "                last_hidden_state=pooled_output,\n",
    "                past_key_values=None,\n",
    "                cross_attentions=None,\n",
    "            )\n",
    "\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphToSequence(nn.Module):\n",
    "    def __init__(self, config: GraphConfig):\n",
    "        super().__init__()\n",
    "        self.op_embedding_dim = config.embedding_size\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            NODE_OP_CODES + 2, self.op_embedding_dim, padding_idx=121\n",
    "        )\n",
    "\n",
    "    def forward(self, node_sequence, node_opcode, node_feat):\n",
    "        node_features = torch.concat(\n",
    "            [node_feat, self.embedding(node_opcode)], dim=-1\n",
    "        )  # [bs, # of nodes, feat_dim]\n",
    "        # node_features = self.pre_net(node_features)\n",
    "        gather_indices = torch.where(\n",
    "            node_sequence == -1, torch.zeros_like(node_sequence), node_sequence\n",
    "        ).to(torch.int64)\n",
    "        sequence = torch.gather(\n",
    "            node_features,\n",
    "            1,\n",
    "            gather_indices.unsqueeze(-1).expand(-1, -1, node_features.shape[-1]),\n",
    "        )\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostMLP(nn.Module):\n",
    "    def __init__(self, config: GraphConfig):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(config.embedding_size + 140 + 24, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.GELU()(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = nn.GELU()(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSequenceEncoder(nn.Module):\n",
    "    def __init__(self, config: GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.graph_sequence = GraphToSequence(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.postnet = PostMLP(config)\n",
    "\n",
    "    def forward(self, node_sequence, node_opcode, node_feat, configs, targets):\n",
    "        sequence = self.graph_sequence(node_sequence, node_opcode, node_feat)\n",
    "        attention_mask = (node_sequence != -1).float()\n",
    "        attention_mask = attention_mask.masked_fill(attention_mask == 0, -1e9)\n",
    "        attention_mask = attention_mask.masked_fill(attention_mask == 1, 0.0)\n",
    "        outputs = self.encoder(sequence, attention_mask)\n",
    "        x = outputs.last_hidden_state\n",
    "        x_replicated = torch.repeat_interleave(x.unsqueeze(1), configs.shape[1], dim=1)\n",
    "        x = torch.cat([x_replicated, configs], dim=-1)\n",
    "        x = self.postnet(x)\n",
    "        x = x.squeeze(-1)\n",
    "        mask = (targets != 0).float()\n",
    "        x = mask * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertSequenceEncoder(config)\n",
    "loss = MultiElementRankLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3022, 0.3571, 0.8268,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [4.5267, 0.4191, 0.6969,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8229, 0.1834, 0.1814,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.9943, 0.3271, 0.2575,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1317, 0.4084, 0.5718,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8673, 0.3081, 0.3596,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)\n",
      "tensor(0., grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "for (\n",
    "    padded_sequence,\n",
    "    padded_opcode,\n",
    "    padded_feat,\n",
    "    padded_config,\n",
    "    config_mask,\n",
    "    padded_target,\n",
    ") in train_loader:\n",
    "    outputs = model(\n",
    "        padded_sequence, padded_opcode, padded_feat, padded_config, padded_target\n",
    "    )\n",
    "    print(outputs)\n",
    "    mask = (outputs != 0.0).int()\n",
    "    print(mask)\n",
    "    error = loss(outputs, padded_target, mask)\n",
    "    print(error)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiElementRankLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function that compares the output of the model with the output of the model with a permutation of the elements\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin: float = 0.0, number_permutations: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.loss_fn = torch.nn.MarginRankingLoss(margin=margin, reduction=\"none\")\n",
    "        self.number_permutations = number_permutations\n",
    "\n",
    "    def calculate_rank_loss(\n",
    "        self,\n",
    "        outputs: torch.Tensor,\n",
    "        config_runtime: torch.Tensor,\n",
    "        config_idxs: torch.Tensor,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generates a permutation of the predictions and targets and calculates the loss MarginRankingLoss against the permutation\n",
    "        Args:\n",
    "            outputs: Tensor of shape (bs, seq_len) with the outputs of the model\n",
    "            config_runtime: Tensor of shape (bs, seq_len) with the runtime of the model\n",
    "            config_mask: Tensor of shape (bs, seq_len) with 1 in the positions of the elements\n",
    "            and 0 in the positions of the padding\n",
    "        Returns:\n",
    "            loss: Tensor of shape (bs, seq_len) with the loss for each element in the batch\n",
    "        \"\"\"\n",
    "        bs, num_configs = outputs.shape\n",
    "        permutation = torch.randperm(num_configs)\n",
    "        permuted_idxs = config_idxs[:, permutation]\n",
    "        # We mask those cases where we compare the same configuration\n",
    "        config_mask = torch.where(config_idxs != permuted_idxs, 1, 0)\n",
    "        permuted_runtime = config_runtime[:, permutation]\n",
    "        labels = 2 * ((config_runtime - permuted_runtime) > 0) - 1\n",
    "        print(labels)\n",
    "        permuted_output = outputs[:, permutation]\n",
    "        loss = self.loss_fn(\n",
    "            outputs.view(-1, 1), permuted_output.view(-1, 1), labels.view(-1, 1)\n",
    "        )\n",
    "        print(loss)\n",
    "        loss = loss.view(bs, num_configs) * config_mask\n",
    "        return loss.mean()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        outputs: torch.Tensor,\n",
    "        config_runtime: torch.Tensor,\n",
    "        config_idxs: torch.Tensor,\n",
    "    ):\n",
    "        loss = 0\n",
    "        for _ in range(self.number_permutations):\n",
    "            loss += self.calculate_rank_loss(outputs, config_runtime, config_idxs)\n",
    "        return loss / self.number_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileTopK(tm.Metric):\n",
    "    higher_is_better = True\n",
    "\n",
    "    def __init__(self, k: int = 5) -> None:\n",
    "        super().__init__()\n",
    "        self.add_state(\"runtimes\", default=[], dist_reduce_fx=None)\n",
    "        self.k = k\n",
    "\n",
    "    def update(\n",
    "        self, preds: torch.Tensor, target: torch.Tensor, config_attn_mask: torch.Tensor\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Update the metric state\n",
    "        Args:\n",
    "            preds: Tensor of shape (bs, seq_len) with the predicted runtimes orders\n",
    "            target: Tensor of shape (bs, seq_len) with the target runtimes\n",
    "            config_attn_mask: Tensor of shape (bs, seq_len) with 1 in the positions of the elements\n",
    "        \"\"\"\n",
    "        best_runtimes = (\n",
    "            torch.where(config_attn_mask == 1, target, torch.tensor(float(\"inf\")))\n",
    "            .min(1)\n",
    "            .values\n",
    "        )\n",
    "        masked_preds = torch.where(\n",
    "            config_attn_mask == 1, preds, torch.tensor(float(\"inf\"))\n",
    "        )\n",
    "        pred_bottomk_indices = torch.topk(masked_preds, k=self.k, largest=False).indices\n",
    "        bs = preds.shape[0]\n",
    "        bottom_k_positions = torch.stack(\n",
    "            [\n",
    "                torch.arange(bs).repeat_interleave(self.k).to(config_attn_mask.device),\n",
    "                pred_bottomk_indices.view(-1),\n",
    "            ]\n",
    "        )\n",
    "        predicted_runtimes = target[bottom_k_positions[0], bottom_k_positions[1]].view(\n",
    "            bs, self.k\n",
    "        )\n",
    "        best_predicted_runtimes = predicted_runtimes.min(1).values\n",
    "        self.runtimes.append(best_predicted_runtimes / best_runtimes)\n",
    "\n",
    "    def compute(self) -> torch.Tensor:\n",
    "        return (2 - torch.cat(self.runtimes)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseRankingLoss(nn.Module):\n",
    "    def __init__(self, margin: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.MarginRankingLoss(margin=margin)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        mask = (target != 0.0).float()\n",
    "        mask = mask.unsqueeze(-1) * mask.unsqueeze(-2)\n",
    "        diff = preds.unsqueeze(-1) - preds.unsqueeze(-2)\n",
    "        target_diff = target.unsqueeze(-1) - target.unsqueeze(-2)\n",
    "        target_diff = torch.clamp(target_diff, min=0.0)\n",
    "        loss = mask * torch.relu(self.margin + diff * target_diff - self.margin)\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRankingLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomRankingLoss, self).__init__()\n",
    "        self.margin_ranking_loss = nn.MarginRankingLoss(\n",
    "            reduction=\"none\"\n",
    "        )  # none to handle averaging manually\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        mask = target > 0\n",
    "        target_diffs = target.unsqueeze(2) - target.unsqueeze(1)\n",
    "        pred_diffs = pred.unsqueeze(2) - pred.unsqueeze(1)\n",
    "        labels = torch.sign(target_diffs)\n",
    "        mask_diffs = mask.unsqueeze(2) & mask.unsqueeze(1)\n",
    "        labels = labels * mask_diffs.float()\n",
    "        losses = self.margin_ranking_loss(\n",
    "            pred_diffs, torch.zeros_like(pred_diffs), labels\n",
    "        )\n",
    "        avg_loss = losses.sum() / mask_diffs.float().sum()\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRankingLoss(nn.Module):\n",
    "    def __init__(self, chunk_size=1000):\n",
    "        super(CustomRankingLoss, self).__init__()\n",
    "        self.margin_ranking_loss = nn.MarginRankingLoss(\n",
    "            reduction=\"none\"\n",
    "        )  # none to handle averaging manually\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def compute_chunked_loss(self, pred, target, mask):\n",
    "        # Break the computation into chunks to save memory\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        num_configs = pred.size(1)\n",
    "        for i in range(0, num_configs, self.chunk_size):\n",
    "            for j in range(0, num_configs, self.chunk_size):\n",
    "                target_diffs = target[:, i : i + self.chunk_size].unsqueeze(2) - target[\n",
    "                    :, j : j + self.chunk_size\n",
    "                ].unsqueeze(1)\n",
    "                pred_diffs = pred[:, i : i + self.chunk_size].unsqueeze(2) - pred[\n",
    "                    :, j : j + self.chunk_size\n",
    "                ].unsqueeze(1)\n",
    "\n",
    "                labels = torch.sign(target_diffs)\n",
    "\n",
    "                mask_diffs = mask[:, i : i + self.chunk_size].unsqueeze(2) & mask[\n",
    "                    :, j : j + self.chunk_size\n",
    "                ].unsqueeze(1)\n",
    "                labels = labels * mask_diffs.float()\n",
    "\n",
    "                losses = self.margin_ranking_loss(\n",
    "                    pred_diffs, torch.zeros_like(pred_diffs), labels\n",
    "                )\n",
    "\n",
    "                total_loss += losses.sum()\n",
    "                total_count += mask_diffs.float().sum()\n",
    "\n",
    "        avg_loss = total_loss / total_count\n",
    "        return avg_loss\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        mask = target > 0\n",
    "        return self.compute_chunked_loss(pred, target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningWrapper(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, loss: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.topk = TileTopK()\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        return self.model(*inputs)\n",
    "\n",
    "    def compute_loss(self, outputs, target, mask=None):\n",
    "        if mask is None:\n",
    "            mask = (outputs != 0.0).int()\n",
    "        return self.loss(outputs, target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs = batch[:-1]\n",
    "        target = batch[-1]\n",
    "        outputs = self.model(*inputs)\n",
    "        error = self.compute_loss(outputs, target)\n",
    "        self.log(\"loss\", error, prog_bar=True)\n",
    "        return {\"loss\": error}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs = batch[:-1]\n",
    "        target = batch[-1]\n",
    "        outputs = self.model(*inputs)\n",
    "        error = self.compute_loss(outputs, target)\n",
    "        self.log(\"val_loss\", error, prog_bar=True)\n",
    "\n",
    "        mask = (outputs != 0.0).int()\n",
    "        self.topk.update(outputs, target, mask)\n",
    "        return {\"val_loss\": error}\n",
    "\n",
    "    def on_validation_end(self) -> None:\n",
    "        topk = self.topk.compute()\n",
    "        self.print(f\"topk {topk:.3f}\")\n",
    "        self.topk.reset()\n",
    "        return super().on_validation_end()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs = batch[:-1]\n",
    "        target = batch[-1]\n",
    "        outputs = self.model(*inputs)\n",
    "        error = self.compute_loss(outputs, target)\n",
    "        self.log(\"test_loss\", error, prog_bar=True)\n",
    "        return {\"test_loss\": error}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningWrapper(BertSequenceEncoder(config), CustomRankingLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TileDataset(tile_xla[\"train\"])\n",
    "valid_dataset = TileDataset(tile_xla[\"valid\"])\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=custom_collate,\n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, collate_fn=custom_collate, batch_size=2, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer_config = dict(\n",
    "    max_epochs=50,\n",
    "    # precision=32,\n",
    "    gradient_clip_val=1.0,\n",
    "    accumulate_grad_batches=2,\n",
    "    check_val_every_n_epoch=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281dada33e194eb0842e106a46cfc909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73559cc9cfe48988cca3705154248a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2ddb9c398844d5a992ec5366493a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0791f0a4fa374c93a66559d031f6bdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15007442d5134cb8add7f83cf3215748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cb6408758b4e1985ba0caeb954ac4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab0fbfe734a4473b70416c8cd438794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.979\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "model.to(device)\n",
    "model = model.train()\n",
    "# torch.set_float32_matmul_precision(\"medium\")\n",
    "trainer = pl.Trainer(\n",
    "    **trainer_config,\n",
    ")\n",
    "trainer.fit(model, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 30 05:04:24 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.47                 Driver Version: 531.68       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090 Ti      On | 00000000:01:00.0 Off |                  Off |\n",
      "| 45%   57C    P8               16W / 450W|   1445MiB / 24564MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        32      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        33      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A       622      C   /python3.10                               N/A      |\n",
      "|    0   N/A  N/A     20500      C   /python3.10                               N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = model.cpu()\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
