{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 04:38:29.425570: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-25 04:38:29.465332: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpugraphsv1_layout_data_py as layout_data\n",
    "import tpugraphsv1_tile_data_py as tile_data\n",
    "import tpugraphsv1_implicit_py as implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_DATA_ROOT = \"data/tpugraphs/npz_all/npz/tile\"\n",
    "SOURCE = \"xla\"\n",
    "# Batch size information.\n",
    "BATCH_SIZE = 16  # Number of graphs per batch.\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset cache file:  cache/7490bb27786a0492d5d8c97cd93ea98c-cache.npz\n",
      "loaded from cache/7490bb27786a0492d5d8c97cd93ea98c-cache.npz\n",
      "dataset cache file:  cache/f0317cd4ac9bf3f96a3c1cc793b2d0f7-cache.npz\n",
      "loaded from cache/f0317cd4ac9bf3f96a3c1cc793b2d0f7-cache.npz\n",
      "dataset cache file:  cache/7ab25f36687847ece34a214a6390286d-cache.npz\n",
      "loaded from cache/7ab25f36687847ece34a214a6390286d-cache.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 20:11:39.659273: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n",
      "2023-10-25 20:11:39.661254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n",
      "2023-10-25 20:11:40.016199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n",
      "2023-10-25 20:11:40.017413: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n"
     ]
    }
   ],
   "source": [
    "tile_data_root_dir = os.path.join(os.path.expanduser(TILE_DATA_ROOT), SOURCE)\n",
    "\n",
    "tile_npz_dataset = tile_data.get_npz_dataset(\n",
    "    tile_data_root_dir,\n",
    "    cache_dir=\"cache\",\n",
    ")\n",
    "\n",
    "\n",
    "def pair_tile_graph_with_label(graph: tfgnn.GraphTensor):\n",
    "    \"\"\"Extracts label from graph (`tfgnn.GraphTensor`) and returns a pair of `(graph, label)`\"\"\"\n",
    "    # Return runtimes divded over large number: only ranking is required. The\n",
    "    # runtimes are in the 100K range\n",
    "    label = tf.cast(\n",
    "        tf.cast(graph.node_sets[\"config\"][\"runtimes\"], tf.float64)\n",
    "        * tf.cast(graph.node_sets[\"config\"][\"normalizers\"], tf.float64)\n",
    "        / 1e6,\n",
    "        tf.float32,\n",
    "    )\n",
    "    label = tf.RaggedTensor.from_row_lengths(\n",
    "        values=label, row_lengths=graph.node_sets[\"config\"].sizes\n",
    "    )\n",
    "    return graph, label\n",
    "\n",
    "\n",
    "# def duplicate_and_shuffle(graph: tfgnn.GraphTensor):\n",
    "#     graphs = [graph]*10\n",
    "#     for i in range(1, 10):\n",
    "#         graphs[i] = tfgnn.shuffle_nodes(graphs[i])\n",
    "\n",
    "#     return graphs\n",
    "\n",
    "# def graph_generator():\n",
    "#     for graph in expanded_graph_list[::-1]:\n",
    "#         yield graph\n",
    "\n",
    "# graph_list = [graph for graph in tile_npz_dataset.train.get_graph_tensors_dataset()]\n",
    "# expanded_graph_list = []\n",
    "# for graph in graph_list:\n",
    "#     expanded_graph_list.extend([tfgnn.shuffle_nodes(graph) for _ in range(5)])\n",
    "\n",
    "\n",
    "# tile_train_ds = (\n",
    "#     tfgnn.dataset_from_generator(\n",
    "#         graph_generator)  # Assuming tfgnn.GraphTensor has a method get_output_signature\n",
    "#     .shuffle(1000, reshuffle_each_iteration=True)\n",
    "#     .batch(BATCH_SIZE, drop_remainder=False)\n",
    "#     .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "#     .map(pair_tile_graph_with_label)\n",
    "# )\n",
    "\n",
    "\n",
    "tile_train_ds = (\n",
    "    tile_npz_dataset.train.get_graph_tensors_dataset()\n",
    "    .shuffle(1000, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE, drop_remainder=False)\n",
    "    .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "    .map(pair_tile_graph_with_label)\n",
    ")\n",
    "\n",
    "tile_valid_ds = (\n",
    "    tile_npz_dataset.validation.get_graph_tensors_dataset()\n",
    "    .batch(BATCH_SIZE, drop_remainder=False)\n",
    "    .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "    .map(pair_tile_graph_with_label)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 20:11:49.620308: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [10948088,21]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2023-10-25 20:11:49.620587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [5710]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.076494, shape=(), dtype=float32)\n",
      "tf.Tensor(0.96887785, shape=(), dtype=float32)\n",
      "tf.Tensor(26.407364, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6562853, shape=(), dtype=float32)\n",
      "tf.Tensor(85.43768, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5555634, shape=(), dtype=float32)\n",
      "tf.Tensor(162.65909, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0102487, shape=(), dtype=float32)\n",
      "tf.Tensor(45.617104, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8511388, shape=(), dtype=float32)\n",
      "tf.Tensor(140.4183, shape=(), dtype=float32)\n",
      "tf.Tensor(4.774052, shape=(), dtype=float32)\n",
      "tf.Tensor(116.67026, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5320122, shape=(), dtype=float32)\n",
      "tf.Tensor(36.537445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8907146, shape=(), dtype=float32)\n",
      "tf.Tensor(82.94983, shape=(), dtype=float32)\n",
      "tf.Tensor(2.341325, shape=(), dtype=float32)\n",
      "tf.Tensor(71.33319, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8833634, shape=(), dtype=float32)\n",
      "tf.Tensor(75.05835, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9665134, shape=(), dtype=float32)\n",
      "tf.Tensor(627.0853, shape=(), dtype=float32)\n",
      "tf.Tensor(8.246036, shape=(), dtype=float32)\n",
      "tf.Tensor(23.494093, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0542008, shape=(), dtype=float32)\n",
      "tf.Tensor(418.27426, shape=(), dtype=float32)\n",
      "tf.Tensor(5.2790585, shape=(), dtype=float32)\n",
      "tf.Tensor(65.515, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2978108, shape=(), dtype=float32)\n",
      "tf.Tensor(82.00205, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3170286, shape=(), dtype=float32)\n",
      "tf.Tensor(72.40349, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5388681, shape=(), dtype=float32)\n",
      "tf.Tensor(644.1348, shape=(), dtype=float32)\n",
      "tf.Tensor(6.6211734, shape=(), dtype=float32)\n",
      "tf.Tensor(21.042164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6701181, shape=(), dtype=float32)\n",
      "tf.Tensor(400.8995, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5763597, shape=(), dtype=float32)\n",
      "tf.Tensor(55.773804, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6617872, shape=(), dtype=float32)\n",
      "tf.Tensor(70.8234, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3406552, shape=(), dtype=float32)\n",
      "tf.Tensor(1150.1414, shape=(), dtype=float32)\n",
      "tf.Tensor(11.168068, shape=(), dtype=float32)\n",
      "tf.Tensor(283.34882, shape=(), dtype=float32)\n",
      "tf.Tensor(6.15086, shape=(), dtype=float32)\n",
      "tf.Tensor(6318.044, shape=(), dtype=float32)\n",
      "tf.Tensor(65.11917, shape=(), dtype=float32)\n",
      "tf.Tensor(1206.866, shape=(), dtype=float32)\n",
      "tf.Tensor(10.408945, shape=(), dtype=float32)\n",
      "tf.Tensor(4388.8696, shape=(), dtype=float32)\n",
      "tf.Tensor(41.42805, shape=(), dtype=float32)\n",
      "tf.Tensor(9199.148, shape=(), dtype=float32)\n",
      "tf.Tensor(76.83269, shape=(), dtype=float32)\n",
      "tf.Tensor(2546.0469, shape=(), dtype=float32)\n",
      "tf.Tensor(38.72088, shape=(), dtype=float32)\n",
      "tf.Tensor(8192.946, shape=(), dtype=float32)\n",
      "tf.Tensor(19.537252, shape=(), dtype=float32)\n",
      "tf.Tensor(332.54007, shape=(), dtype=float32)\n",
      "tf.Tensor(4.681806, shape=(), dtype=float32)\n",
      "tf.Tensor(26939.861, shape=(), dtype=float32)\n",
      "tf.Tensor(114.74152, shape=(), dtype=float32)\n",
      "tf.Tensor(4077.7725, shape=(), dtype=float32)\n",
      "tf.Tensor(5.605474, shape=(), dtype=float32)\n",
      "tf.Tensor(1932.8911, shape=(), dtype=float32)\n",
      "tf.Tensor(14.471905, shape=(), dtype=float32)\n",
      "tf.Tensor(5254.174, shape=(), dtype=float32)\n",
      "tf.Tensor(150.56454, shape=(), dtype=float32)\n",
      "tf.Tensor(115.18602, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4786177, shape=(), dtype=float32)\n",
      "tf.Tensor(64.683525, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3097427, shape=(), dtype=float32)\n",
      "tf.Tensor(5091.4053, shape=(), dtype=float32)\n",
      "tf.Tensor(26.565351, shape=(), dtype=float32)\n",
      "tf.Tensor(198.45107, shape=(), dtype=float32)\n",
      "tf.Tensor(8.399848, shape=(), dtype=float32)\n",
      "tf.Tensor(70.79183, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1886338, shape=(), dtype=float32)\n",
      "tf.Tensor(228.32692, shape=(), dtype=float32)\n",
      "tf.Tensor(3.686669, shape=(), dtype=float32)\n",
      "tf.Tensor(13499.134, shape=(), dtype=float32)\n",
      "tf.Tensor(22.038528, shape=(), dtype=float32)\n",
      "tf.Tensor(4924.3096, shape=(), dtype=float32)\n",
      "tf.Tensor(7.042834, shape=(), dtype=float32)\n",
      "tf.Tensor(632.5466, shape=(), dtype=float32)\n",
      "tf.Tensor(4.531848, shape=(), dtype=float32)\n",
      "tf.Tensor(1013.19293, shape=(), dtype=float32)\n",
      "tf.Tensor(9.165585, shape=(), dtype=float32)\n",
      "tf.Tensor(26.397657, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5723499, shape=(), dtype=float32)\n",
      "tf.Tensor(125.77383, shape=(), dtype=float32)\n",
      "tf.Tensor(2.096356, shape=(), dtype=float32)\n",
      "tf.Tensor(255.58752, shape=(), dtype=float32)\n",
      "tf.Tensor(3.421648, shape=(), dtype=float32)\n",
      "tf.Tensor(1887.666, shape=(), dtype=float32)\n",
      "tf.Tensor(8.823918, shape=(), dtype=float32)\n",
      "tf.Tensor(264.7011, shape=(), dtype=float32)\n",
      "tf.Tensor(2.8368053, shape=(), dtype=float32)\n",
      "tf.Tensor(378.14374, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6428626, shape=(), dtype=float32)\n",
      "tf.Tensor(65.68489, shape=(), dtype=float32)\n",
      "tf.Tensor(3.2459273, shape=(), dtype=float32)\n",
      "tf.Tensor(93.76088, shape=(), dtype=float32)\n",
      "tf.Tensor(3.394045, shape=(), dtype=float32)\n",
      "tf.Tensor(105.19914, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0806751, shape=(), dtype=float32)\n",
      "tf.Tensor(3520.0408, shape=(), dtype=float32)\n",
      "tf.Tensor(93.707695, shape=(), dtype=float32)\n",
      "tf.Tensor(237.22827, shape=(), dtype=float32)\n",
      "tf.Tensor(2.331297, shape=(), dtype=float32)\n",
      "tf.Tensor(1758.8625, shape=(), dtype=float32)\n",
      "tf.Tensor(32.780277, shape=(), dtype=float32)\n",
      "tf.Tensor(1619.3556, shape=(), dtype=float32)\n",
      "tf.Tensor(21.881392, shape=(), dtype=float32)\n",
      "tf.Tensor(281.5734, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2565675, shape=(), dtype=float32)\n",
      "tf.Tensor(174.94853, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3840647, shape=(), dtype=float32)\n",
      "tf.Tensor(59.90452, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1554232, shape=(), dtype=float32)\n",
      "tf.Tensor(34.052887, shape=(), dtype=float32)\n",
      "tf.Tensor(0.88638777, shape=(), dtype=float32)\n",
      "tf.Tensor(1611.5433, shape=(), dtype=float32)\n",
      "tf.Tensor(14.933365, shape=(), dtype=float32)\n",
      "tf.Tensor(218.08463, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0879588, shape=(), dtype=float32)\n",
      "tf.Tensor(218.24945, shape=(), dtype=float32)\n",
      "tf.Tensor(5.6658077, shape=(), dtype=float32)\n",
      "tf.Tensor(250.62128, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1438649, shape=(), dtype=float32)\n",
      "tf.Tensor(51.00994, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3948865, shape=(), dtype=float32)\n",
      "tf.Tensor(5254.412, shape=(), dtype=float32)\n",
      "tf.Tensor(98.81166, shape=(), dtype=float32)\n",
      "tf.Tensor(42.794823, shape=(), dtype=float32)\n",
      "tf.Tensor(0.76617837, shape=(), dtype=float32)\n",
      "tf.Tensor(189.07198, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1404054, shape=(), dtype=float32)\n",
      "tf.Tensor(330.8748, shape=(), dtype=float32)\n",
      "tf.Tensor(4.374213, shape=(), dtype=float32)\n",
      "tf.Tensor(209.5767, shape=(), dtype=float32)\n",
      "tf.Tensor(3.337457, shape=(), dtype=float32)\n",
      "tf.Tensor(99.20129, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0091875, shape=(), dtype=float32)\n",
      "tf.Tensor(377.49997, shape=(), dtype=float32)\n",
      "tf.Tensor(4.078519, shape=(), dtype=float32)\n",
      "tf.Tensor(150.14851, shape=(), dtype=float32)\n",
      "tf.Tensor(3.8876088, shape=(), dtype=float32)\n",
      "tf.Tensor(3131.636, shape=(), dtype=float32)\n",
      "tf.Tensor(73.91697, shape=(), dtype=float32)\n",
      "tf.Tensor(50.700874, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0327287, shape=(), dtype=float32)\n",
      "tf.Tensor(151.25766, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7354702, shape=(), dtype=float32)\n",
      "tf.Tensor(133.12053, shape=(), dtype=float32)\n",
      "tf.Tensor(13.195984, shape=(), dtype=float32)\n",
      "tf.Tensor(71.42375, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7571144, shape=(), dtype=float32)\n",
      "tf.Tensor(93.66153, shape=(), dtype=float32)\n",
      "tf.Tensor(2.8260176, shape=(), dtype=float32)\n",
      "tf.Tensor(299.3244, shape=(), dtype=float32)\n",
      "tf.Tensor(4.070519, shape=(), dtype=float32)\n",
      "tf.Tensor(111.670456, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8501843, shape=(), dtype=float32)\n",
      "tf.Tensor(244.27785, shape=(), dtype=float32)\n",
      "tf.Tensor(7.7753744, shape=(), dtype=float32)\n",
      "tf.Tensor(1302.2821, shape=(), dtype=float32)\n",
      "tf.Tensor(16.887087, shape=(), dtype=float32)\n",
      "tf.Tensor(766.7748, shape=(), dtype=float32)\n",
      "tf.Tensor(9.935043, shape=(), dtype=float32)\n",
      "tf.Tensor(152.19823, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9100783, shape=(), dtype=float32)\n",
      "tf.Tensor(95.846886, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7995962, shape=(), dtype=float32)\n",
      "tf.Tensor(640.61237, shape=(), dtype=float32)\n",
      "tf.Tensor(7.0098124, shape=(), dtype=float32)\n",
      "tf.Tensor(826.1735, shape=(), dtype=float32)\n",
      "tf.Tensor(9.522381, shape=(), dtype=float32)\n",
      "tf.Tensor(54.021187, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8307732, shape=(), dtype=float32)\n",
      "tf.Tensor(56.79133, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4938902, shape=(), dtype=float32)\n",
      "tf.Tensor(144.72021, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4715948, shape=(), dtype=float32)\n",
      "tf.Tensor(110.12051, shape=(), dtype=float32)\n",
      "tf.Tensor(2.057417, shape=(), dtype=float32)\n",
      "tf.Tensor(236.33926, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6636436, shape=(), dtype=float32)\n",
      "tf.Tensor(5090.1025, shape=(), dtype=float32)\n",
      "tf.Tensor(42.715553, shape=(), dtype=float32)\n",
      "tf.Tensor(76.540794, shape=(), dtype=float32)\n",
      "tf.Tensor(1.288948, shape=(), dtype=float32)\n",
      "tf.Tensor(175.50916, shape=(), dtype=float32)\n",
      "tf.Tensor(2.480014, shape=(), dtype=float32)\n",
      "tf.Tensor(220.3193, shape=(), dtype=float32)\n",
      "tf.Tensor(2.711826, shape=(), dtype=float32)\n",
      "tf.Tensor(1226.5275, shape=(), dtype=float32)\n",
      "tf.Tensor(9.365142, shape=(), dtype=float32)\n",
      "tf.Tensor(1111.5018, shape=(), dtype=float32)\n",
      "tf.Tensor(10.163364, shape=(), dtype=float32)\n",
      "tf.Tensor(55.09736, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7640474, shape=(), dtype=float32)\n",
      "tf.Tensor(41.75364, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6099492, shape=(), dtype=float32)\n",
      "tf.Tensor(892.2025, shape=(), dtype=float32)\n",
      "tf.Tensor(21.72441, shape=(), dtype=float32)\n",
      "tf.Tensor(16407.736, shape=(), dtype=float32)\n",
      "tf.Tensor(31.55413, shape=(), dtype=float32)\n",
      "tf.Tensor(4813.748, shape=(), dtype=float32)\n",
      "tf.Tensor(36.717873, shape=(), dtype=float32)\n",
      "tf.Tensor(176.15297, shape=(), dtype=float32)\n",
      "tf.Tensor(3.92033, shape=(), dtype=float32)\n",
      "tf.Tensor(1150.1415, shape=(), dtype=float32)\n",
      "tf.Tensor(9.722363, shape=(), dtype=float32)\n",
      "tf.Tensor(151.81602, shape=(), dtype=float32)\n",
      "tf.Tensor(4.123873, shape=(), dtype=float32)\n",
      "tf.Tensor(55.540623, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9292554, shape=(), dtype=float32)\n",
      "tf.Tensor(63.770756, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5759078, shape=(), dtype=float32)\n",
      "tf.Tensor(195.68593, shape=(), dtype=float32)\n",
      "tf.Tensor(7.2580733, shape=(), dtype=float32)\n",
      "tf.Tensor(1332.2446, shape=(), dtype=float32)\n",
      "tf.Tensor(20.93477, shape=(), dtype=float32)\n",
      "tf.Tensor(582.1739, shape=(), dtype=float32)\n",
      "tf.Tensor(10.637827, shape=(), dtype=float32)\n",
      "tf.Tensor(48.921707, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4930897, shape=(), dtype=float32)\n",
      "tf.Tensor(247.6647, shape=(), dtype=float32)\n",
      "tf.Tensor(5.033124, shape=(), dtype=float32)\n",
      "tf.Tensor(751.8967, shape=(), dtype=float32)\n",
      "tf.Tensor(9.261813, shape=(), dtype=float32)\n",
      "tf.Tensor(57.611786, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8285455, shape=(), dtype=float32)\n",
      "tf.Tensor(275.52722, shape=(), dtype=float32)\n",
      "tf.Tensor(4.275944, shape=(), dtype=float32)\n",
      "tf.Tensor(277.87347, shape=(), dtype=float32)\n",
      "tf.Tensor(5.6067114, shape=(), dtype=float32)\n",
      "tf.Tensor(151.8917, shape=(), dtype=float32)\n",
      "tf.Tensor(2.8035653, shape=(), dtype=float32)\n",
      "tf.Tensor(754.0226, shape=(), dtype=float32)\n",
      "tf.Tensor(7.6679983, shape=(), dtype=float32)\n",
      "tf.Tensor(156.0017, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1583881, shape=(), dtype=float32)\n",
      "tf.Tensor(175.24933, shape=(), dtype=float32)\n",
      "tf.Tensor(3.3464885, shape=(), dtype=float32)\n",
      "tf.Tensor(215.95941, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9729158, shape=(), dtype=float32)\n",
      "tf.Tensor(998.8339, shape=(), dtype=float32)\n",
      "tf.Tensor(9.814883, shape=(), dtype=float32)\n",
      "tf.Tensor(383.68384, shape=(), dtype=float32)\n",
      "tf.Tensor(5.7129827, shape=(), dtype=float32)\n",
      "tf.Tensor(250.59357, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1720502, shape=(), dtype=float32)\n",
      "tf.Tensor(175.49971, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1892362, shape=(), dtype=float32)\n",
      "tf.Tensor(57.022717, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6300665, shape=(), dtype=float32)\n",
      "tf.Tensor(226.88693, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6705055, shape=(), dtype=float32)\n",
      "tf.Tensor(507.046, shape=(), dtype=float32)\n",
      "tf.Tensor(3.7020533, shape=(), dtype=float32)\n",
      "tf.Tensor(298.5334, shape=(), dtype=float32)\n",
      "tf.Tensor(3.6080663, shape=(), dtype=float32)\n",
      "tf.Tensor(48.92197, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2558602, shape=(), dtype=float32)\n",
      "tf.Tensor(83.40812, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9602118, shape=(), dtype=float32)\n",
      "tf.Tensor(236.33994, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5140352, shape=(), dtype=float32)\n",
      "tf.Tensor(156.00055, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0072722, shape=(), dtype=float32)\n",
      "tf.Tensor(302.51465, shape=(), dtype=float32)\n",
      "tf.Tensor(4.5398145, shape=(), dtype=float32)\n",
      "tf.Tensor(150.3095, shape=(), dtype=float32)\n",
      "tf.Tensor(3.312639, shape=(), dtype=float32)\n",
      "tf.Tensor(1286.2885, shape=(), dtype=float32)\n",
      "tf.Tensor(14.929395, shape=(), dtype=float32)\n",
      "tf.Tensor(49.073032, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9030848, shape=(), dtype=float32)\n",
      "tf.Tensor(63.86307, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6029073, shape=(), dtype=float32)\n",
      "tf.Tensor(155.6657, shape=(), dtype=float32)\n",
      "tf.Tensor(3.2329347, shape=(), dtype=float32)\n",
      "tf.Tensor(23.735052, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2315462, shape=(), dtype=float32)\n",
      "tf.Tensor(103.620186, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1714487, shape=(), dtype=float32)\n",
      "tf.Tensor(210.36177, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5230927, shape=(), dtype=float32)\n",
      "tf.Tensor(295.7384, shape=(), dtype=float32)\n",
      "tf.Tensor(5.8581257, shape=(), dtype=float32)\n",
      "tf.Tensor(116.99989, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3234396, shape=(), dtype=float32)\n",
      "tf.Tensor(156.00067, shape=(), dtype=float32)\n",
      "tf.Tensor(4.574412, shape=(), dtype=float32)\n",
      "tf.Tensor(61.746826, shape=(), dtype=float32)\n",
      "tf.Tensor(1.917574, shape=(), dtype=float32)\n",
      "tf.Tensor(175.50032, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9985132, shape=(), dtype=float32)\n",
      "tf.Tensor(330.87585, shape=(), dtype=float32)\n",
      "tf.Tensor(4.269634, shape=(), dtype=float32)\n",
      "tf.Tensor(24.06155, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2613248, shape=(), dtype=float32)\n",
      "tf.Tensor(175.49982, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0427113, shape=(), dtype=float32)\n",
      "tf.Tensor(43.875477, shape=(), dtype=float32)\n",
      "tf.Tensor(0.98106724, shape=(), dtype=float32)\n",
      "tf.Tensor(702.93494, shape=(), dtype=float32)\n",
      "tf.Tensor(4.9669485, shape=(), dtype=float32)\n",
      "tf.Tensor(298.52954, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4627306, shape=(), dtype=float32)\n",
      "tf.Tensor(89.47241, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8538381, shape=(), dtype=float32)\n",
      "tf.Tensor(204.64062, shape=(), dtype=float32)\n",
      "tf.Tensor(3.5532467, shape=(), dtype=float32)\n",
      "tf.Tensor(205.62053, shape=(), dtype=float32)\n",
      "tf.Tensor(3.7100606, shape=(), dtype=float32)\n",
      "tf.Tensor(175.49973, shape=(), dtype=float32)\n",
      "tf.Tensor(3.5953064, shape=(), dtype=float32)\n",
      "tf.Tensor(39.000496, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0140879, shape=(), dtype=float32)\n",
      "tf.Tensor(155.99991, shape=(), dtype=float32)\n",
      "tf.Tensor(2.965495, shape=(), dtype=float32)\n",
      "tf.Tensor(319.62128, shape=(), dtype=float32)\n",
      "tf.Tensor(3.3481817, shape=(), dtype=float32)\n",
      "tf.Tensor(316.70047, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0452375, shape=(), dtype=float32)\n",
      "tf.Tensor(36.69175, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1326302, shape=(), dtype=float32)\n",
      "tf.Tensor(95.60189, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3110766, shape=(), dtype=float32)\n",
      "tf.Tensor(1192.9062, shape=(), dtype=float32)\n",
      "tf.Tensor(14.145785, shape=(), dtype=float32)\n",
      "tf.Tensor(220.14467, shape=(), dtype=float32)\n",
      "tf.Tensor(3.9168136, shape=(), dtype=float32)\n",
      "tf.Tensor(221.08322, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2240515, shape=(), dtype=float32)\n",
      "tf.Tensor(124.78713, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8348134, shape=(), dtype=float32)\n",
      "tf.Tensor(74.92164, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0738575, shape=(), dtype=float32)\n",
      "tf.Tensor(232.32823, shape=(), dtype=float32)\n",
      "tf.Tensor(3.477722, shape=(), dtype=float32)\n",
      "tf.Tensor(95.722984, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6284523, shape=(), dtype=float32)\n",
      "tf.Tensor(205.62013, shape=(), dtype=float32)\n",
      "tf.Tensor(3.303697, shape=(), dtype=float32)\n",
      "tf.Tensor(266.3516, shape=(), dtype=float32)\n",
      "tf.Tensor(4.967347, shape=(), dtype=float32)\n",
      "tf.Tensor(41.617886, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1221408, shape=(), dtype=float32)\n",
      "tf.Tensor(122.30257, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4685295, shape=(), dtype=float32)\n",
      "tf.Tensor(69.33401, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3073723, shape=(), dtype=float32)\n",
      "tf.Tensor(175.50044, shape=(), dtype=float32)\n",
      "tf.Tensor(3.2124534, shape=(), dtype=float32)\n",
      "tf.Tensor(763.4341, shape=(), dtype=float32)\n",
      "tf.Tensor(9.397504, shape=(), dtype=float32)\n",
      "tf.Tensor(67.77216, shape=(), dtype=float32)\n",
      "tf.Tensor(1.726389, shape=(), dtype=float32)\n",
      "tf.Tensor(274.37445, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9835362, shape=(), dtype=float32)\n",
      "tf.Tensor(218.06598, shape=(), dtype=float32)\n",
      "tf.Tensor(3.042609, shape=(), dtype=float32)\n",
      "tf.Tensor(826.2071, shape=(), dtype=float32)\n",
      "tf.Tensor(9.71397, shape=(), dtype=float32)\n",
      "tf.Tensor(117.41146, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2004814, shape=(), dtype=float32)\n",
      "tf.Tensor(81.06262, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5192893, shape=(), dtype=float32)\n",
      "tf.Tensor(117.001, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7005583, shape=(), dtype=float32)\n",
      "tf.Tensor(48.921597, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3053793, shape=(), dtype=float32)\n",
      "tf.Tensor(220.8236, shape=(), dtype=float32)\n",
      "tf.Tensor(4.293487, shape=(), dtype=float32)\n",
      "tf.Tensor(152.06386, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4037206, shape=(), dtype=float32)\n",
      "tf.Tensor(67.13959, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9689362, shape=(), dtype=float32)\n",
      "tf.Tensor(61.087208, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2789173, shape=(), dtype=float32)\n",
      "tf.Tensor(264.7143, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4025495, shape=(), dtype=float32)\n",
      "tf.Tensor(80.59539, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4530933, shape=(), dtype=float32)\n",
      "tf.Tensor(233.11382, shape=(), dtype=float32)\n",
      "tf.Tensor(4.9227815, shape=(), dtype=float32)\n",
      "tf.Tensor(387.5148, shape=(), dtype=float32)\n",
      "tf.Tensor(5.201511, shape=(), dtype=float32)\n",
      "tf.Tensor(315.3245, shape=(), dtype=float32)\n",
      "tf.Tensor(3.937639, shape=(), dtype=float32)\n",
      "tf.Tensor(48.92201, shape=(), dtype=float32)\n",
      "tf.Tensor(1.727219, shape=(), dtype=float32)\n",
      "tf.Tensor(67.74302, shape=(), dtype=float32)\n",
      "tf.Tensor(1.994264, shape=(), dtype=float32)\n",
      "tf.Tensor(952.3892, shape=(), dtype=float32)\n",
      "tf.Tensor(13.584043, shape=(), dtype=float32)\n",
      "tf.Tensor(168.01648, shape=(), dtype=float32)\n",
      "tf.Tensor(2.358184, shape=(), dtype=float32)\n",
      "tf.Tensor(819.17017, shape=(), dtype=float32)\n",
      "tf.Tensor(8.662047, shape=(), dtype=float32)\n",
      "tf.Tensor(170.2459, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9942892, shape=(), dtype=float32)\n",
      "tf.Tensor(129.60678, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0293975, shape=(), dtype=float32)\n",
      "tf.Tensor(155.99986, shape=(), dtype=float32)\n",
      "tf.Tensor(2.626999, shape=(), dtype=float32)\n",
      "tf.Tensor(220.68497, shape=(), dtype=float32)\n",
      "tf.Tensor(5.5271325, shape=(), dtype=float32)\n",
      "tf.Tensor(80.05827, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5030003, shape=(), dtype=float32)\n",
      "tf.Tensor(87.12767, shape=(), dtype=float32)\n",
      "tf.Tensor(2.7142005, shape=(), dtype=float32)\n",
      "tf.Tensor(179.1399, shape=(), dtype=float32)\n",
      "tf.Tensor(3.8012617, shape=(), dtype=float32)\n",
      "tf.Tensor(110.119804, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9198261, shape=(), dtype=float32)\n",
      "tf.Tensor(159.60443, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4579344, shape=(), dtype=float32)\n",
      "tf.Tensor(51.088684, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5642271, shape=(), dtype=float32)\n",
      "tf.Tensor(231.92091, shape=(), dtype=float32)\n",
      "tf.Tensor(3.8860354, shape=(), dtype=float32)\n",
      "tf.Tensor(117.01714, shape=(), dtype=float32)\n",
      "tf.Tensor(2.611143, shape=(), dtype=float32)\n",
      "tf.Tensor(266.2572, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5683744, shape=(), dtype=float32)\n",
      "tf.Tensor(99.18996, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9695766, shape=(), dtype=float32)\n",
      "tf.Tensor(232.3189, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4309542, shape=(), dtype=float32)\n",
      "tf.Tensor(1605.4417, shape=(), dtype=float32)\n",
      "tf.Tensor(13.545295, shape=(), dtype=float32)\n",
      "tf.Tensor(195.19676, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5741642, shape=(), dtype=float32)\n",
      "tf.Tensor(460.38028, shape=(), dtype=float32)\n",
      "tf.Tensor(5.8110185, shape=(), dtype=float32)\n",
      "tf.Tensor(110.07232, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5513556, shape=(), dtype=float32)\n",
      "tf.Tensor(1634.1216, shape=(), dtype=float32)\n",
      "tf.Tensor(13.453189, shape=(), dtype=float32)\n",
      "tf.Tensor(201.82594, shape=(), dtype=float32)\n",
      "tf.Tensor(3.616889, shape=(), dtype=float32)\n",
      "tf.Tensor(205.6201, shape=(), dtype=float32)\n",
      "tf.Tensor(4.58817, shape=(), dtype=float32)\n",
      "tf.Tensor(67.74993, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6299232, shape=(), dtype=float32)\n",
      "tf.Tensor(48.96541, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4757721, shape=(), dtype=float32)\n",
      "tf.Tensor(103.23018, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9975264, shape=(), dtype=float32)\n",
      "tf.Tensor(184.97066, shape=(), dtype=float32)\n",
      "tf.Tensor(3.8375626, shape=(), dtype=float32)\n",
      "tf.Tensor(116.19359, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2184389, shape=(), dtype=float32)\n",
      "tf.Tensor(124.79812, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2952957, shape=(), dtype=float32)\n",
      "tf.Tensor(507.3566, shape=(), dtype=float32)\n",
      "tf.Tensor(3.9521067, shape=(), dtype=float32)\n",
      "tf.Tensor(67.14931, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4857478, shape=(), dtype=float32)\n",
      "tf.Tensor(452.14227, shape=(), dtype=float32)\n",
      "tf.Tensor(3.7245889, shape=(), dtype=float32)\n",
      "tf.Tensor(117.41197, shape=(), dtype=float32)\n",
      "tf.Tensor(2.674038, shape=(), dtype=float32)\n",
      "tf.Tensor(98.10488, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5408099, shape=(), dtype=float32)\n",
      "tf.Tensor(182.7043, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9449892, shape=(), dtype=float32)\n",
      "tf.Tensor(47.552486, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5696164, shape=(), dtype=float32)\n",
      "tf.Tensor(293.31458, shape=(), dtype=float32)\n",
      "tf.Tensor(5.990427, shape=(), dtype=float32)\n",
      "tf.Tensor(232.0979, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4637098, shape=(), dtype=float32)\n",
      "tf.Tensor(103.9596, shape=(), dtype=float32)\n",
      "tf.Tensor(2.144464, shape=(), dtype=float32)\n",
      "tf.Tensor(140.79782, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9327773, shape=(), dtype=float32)\n",
      "tf.Tensor(45.727486, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5079703, shape=(), dtype=float32)\n",
      "tf.Tensor(105.961464, shape=(), dtype=float32)\n",
      "tf.Tensor(1.802592, shape=(), dtype=float32)\n",
      "tf.Tensor(1270.182, shape=(), dtype=float32)\n",
      "tf.Tensor(12.840394, shape=(), dtype=float32)\n",
      "tf.Tensor(47.787964, shape=(), dtype=float32)\n",
      "tf.Tensor(1.532074, shape=(), dtype=float32)\n",
      "tf.Tensor(89.34453, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0037465, shape=(), dtype=float32)\n",
      "tf.Tensor(3519.5774, shape=(), dtype=float32)\n",
      "tf.Tensor(55.35004, shape=(), dtype=float32)\n",
      "tf.Tensor(248.58142, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1185155, shape=(), dtype=float32)\n",
      "tf.Tensor(100.32544, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5303879, shape=(), dtype=float32)\n",
      "tf.Tensor(172.88866, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6868272, shape=(), dtype=float32)\n",
      "tf.Tensor(217.0318, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1169047, shape=(), dtype=float32)\n",
      "tf.Tensor(47.767082, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2256784, shape=(), dtype=float32)\n",
      "tf.Tensor(123.01945, shape=(), dtype=float32)\n",
      "tf.Tensor(2.417797, shape=(), dtype=float32)\n",
      "tf.Tensor(201.82593, shape=(), dtype=float32)\n",
      "tf.Tensor(3.3715749, shape=(), dtype=float32)\n",
      "tf.Tensor(81.48329, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5570532, shape=(), dtype=float32)\n",
      "tf.Tensor(80.36334, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9289343, shape=(), dtype=float32)\n",
      "tf.Tensor(136.35341, shape=(), dtype=float32)\n",
      "tf.Tensor(1.433363, shape=(), dtype=float32)\n",
      "tf.Tensor(47.924, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7634223, shape=(), dtype=float32)\n",
      "tf.Tensor(349.44058, shape=(), dtype=float32)\n",
      "tf.Tensor(3.9381802, shape=(), dtype=float32)\n",
      "tf.Tensor(99.84032, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9309654, shape=(), dtype=float32)\n",
      "tf.Tensor(1956.8634, shape=(), dtype=float32)\n",
      "tf.Tensor(22.5274, shape=(), dtype=float32)\n",
      "tf.Tensor(112.32073, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0456395, shape=(), dtype=float32)\n",
      "tf.Tensor(47.68943, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0110556, shape=(), dtype=float32)\n",
      "tf.Tensor(89.46328, shape=(), dtype=float32)\n",
      "tf.Tensor(1.565769, shape=(), dtype=float32)\n",
      "tf.Tensor(127.59133, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4708626, shape=(), dtype=float32)\n",
      "tf.Tensor(99.84022, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4039083, shape=(), dtype=float32)\n",
      "tf.Tensor(112.32076, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0367699, shape=(), dtype=float32)\n",
      "tf.Tensor(115.67138, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4748244, shape=(), dtype=float32)\n",
      "tf.Tensor(1118.4635, shape=(), dtype=float32)\n",
      "tf.Tensor(20.990757, shape=(), dtype=float32)\n",
      "tf.Tensor(412.88293, shape=(), dtype=float32)\n",
      "tf.Tensor(3.911253, shape=(), dtype=float32)\n",
      "tf.Tensor(44.053574, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3716195, shape=(), dtype=float32)\n",
      "tf.Tensor(25.82126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9847647, shape=(), dtype=float32)\n",
      "tf.Tensor(266.25745, shape=(), dtype=float32)\n",
      "tf.Tensor(3.7835662, shape=(), dtype=float32)\n",
      "tf.Tensor(42.716934, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6662767, shape=(), dtype=float32)\n",
      "tf.Tensor(283.64642, shape=(), dtype=float32)\n",
      "tf.Tensor(4.06769, shape=(), dtype=float32)\n",
      "tf.Tensor(51.163734, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4267691, shape=(), dtype=float32)\n",
      "tf.Tensor(81.17101, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6434139, shape=(), dtype=float32)\n",
      "tf.Tensor(933.0946, shape=(), dtype=float32)\n",
      "tf.Tensor(9.300267, shape=(), dtype=float32)\n",
      "tf.Tensor(220.1471, shape=(), dtype=float32)\n",
      "tf.Tensor(6.087136, shape=(), dtype=float32)\n",
      "tf.Tensor(59.33548, shape=(), dtype=float32)\n",
      "tf.Tensor(1.168991, shape=(), dtype=float32)\n",
      "tf.Tensor(113.17056, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0084348, shape=(), dtype=float32)\n",
      "tf.Tensor(100.33079, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9951608, shape=(), dtype=float32)\n",
      "tf.Tensor(57.508884, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8915386, shape=(), dtype=float32)\n",
      "tf.Tensor(70.86545, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1822298, shape=(), dtype=float32)\n",
      "tf.Tensor(110.0705, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0603693, shape=(), dtype=float32)\n",
      "tf.Tensor(283.45282, shape=(), dtype=float32)\n",
      "tf.Tensor(3.8200936, shape=(), dtype=float32)\n",
      "tf.Tensor(48.92258, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8040953, shape=(), dtype=float32)\n",
      "tf.Tensor(112.320404, shape=(), dtype=float32)\n",
      "tf.Tensor(2.382951, shape=(), dtype=float32)\n",
      "tf.Tensor(99.8409, shape=(), dtype=float32)\n",
      "tf.Tensor(2.576185, shape=(), dtype=float32)\n",
      "tf.Tensor(349.44043, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4803, shape=(), dtype=float32)\n",
      "tf.Tensor(161.81523, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3931723, shape=(), dtype=float32)\n",
      "tf.Tensor(99.84072, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3822763, shape=(), dtype=float32)\n",
      "tf.Tensor(217.94899, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0953326, shape=(), dtype=float32)\n",
      "tf.Tensor(67.1836, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4871767, shape=(), dtype=float32)\n",
      "tf.Tensor(28.080814, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8824936, shape=(), dtype=float32)\n",
      "tf.Tensor(121.50552, shape=(), dtype=float32)\n",
      "tf.Tensor(2.047536, shape=(), dtype=float32)\n",
      "tf.Tensor(12.48091, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38093027, shape=(), dtype=float32)\n",
      "tf.Tensor(99.84159, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2697139, shape=(), dtype=float32)\n",
      "tf.Tensor(12.374085, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3824655, shape=(), dtype=float32)\n",
      "tf.Tensor(113.28799, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0447104, shape=(), dtype=float32)\n",
      "tf.Tensor(199.8506, shape=(), dtype=float32)\n",
      "tf.Tensor(3.8368363, shape=(), dtype=float32)\n",
      "tf.Tensor(89.98229, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7168593, shape=(), dtype=float32)\n",
      "tf.Tensor(40.537365, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0372841, shape=(), dtype=float32)\n",
      "tf.Tensor(106.010826, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9711632, shape=(), dtype=float32)\n",
      "tf.Tensor(32.73845, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3224723, shape=(), dtype=float32)\n",
      "tf.Tensor(1520.0378, shape=(), dtype=float32)\n",
      "tf.Tensor(14.196491, shape=(), dtype=float32)\n",
      "tf.Tensor(1956.8636, shape=(), dtype=float32)\n",
      "tf.Tensor(21.539572, shape=(), dtype=float32)\n",
      "tf.Tensor(161.1408, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2723384, shape=(), dtype=float32)\n",
      "tf.Tensor(21.51163, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7920851, shape=(), dtype=float32)\n",
      "tf.Tensor(37.165417, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2080388, shape=(), dtype=float32)\n",
      "tf.Tensor(45.171013, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2747483, shape=(), dtype=float32)\n",
      "tf.Tensor(57.81691, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8775609, shape=(), dtype=float32)\n",
      "tf.Tensor(33.487007, shape=(), dtype=float32)\n",
      "tf.Tensor(1.274426, shape=(), dtype=float32)\n",
      "tf.Tensor(55.431015, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3139735, shape=(), dtype=float32)\n",
      "tf.Tensor(872.45197, shape=(), dtype=float32)\n",
      "tf.Tensor(8.04002, shape=(), dtype=float32)\n",
      "tf.Tensor(249.60243, shape=(), dtype=float32)\n",
      "tf.Tensor(4.4107003, shape=(), dtype=float32)\n",
      "tf.Tensor(300.86197, shape=(), dtype=float32)\n",
      "tf.Tensor(4.8823047, shape=(), dtype=float32)\n",
      "tf.Tensor(32.417988, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4332418, shape=(), dtype=float32)\n",
      "tf.Tensor(51.16477, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1150757, shape=(), dtype=float32)\n",
      "tf.Tensor(232.52184, shape=(), dtype=float32)\n",
      "tf.Tensor(3.6175182, shape=(), dtype=float32)\n",
      "tf.Tensor(908.7682, shape=(), dtype=float32)\n",
      "tf.Tensor(5.1534677, shape=(), dtype=float32)\n",
      "tf.Tensor(112.3214, shape=(), dtype=float32)\n",
      "tf.Tensor(2.8918822, shape=(), dtype=float32)\n",
      "tf.Tensor(272.6524, shape=(), dtype=float32)\n",
      "tf.Tensor(3.3546727, shape=(), dtype=float32)\n",
      "tf.Tensor(102.56345, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8711823, shape=(), dtype=float32)\n",
      "tf.Tensor(61.833706, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9029905, shape=(), dtype=float32)\n",
      "tf.Tensor(43.44909, shape=(), dtype=float32)\n",
      "tf.Tensor(0.99095494, shape=(), dtype=float32)\n",
      "tf.Tensor(75.05166, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4353577, shape=(), dtype=float32)\n",
      "tf.Tensor(205.62015, shape=(), dtype=float32)\n",
      "tf.Tensor(5.3164806, shape=(), dtype=float32)\n",
      "tf.Tensor(87.36165, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9756671, shape=(), dtype=float32)\n",
      "tf.Tensor(393.12045, shape=(), dtype=float32)\n",
      "tf.Tensor(6.6621203, shape=(), dtype=float32)\n",
      "tf.Tensor(33.884235, shape=(), dtype=float32)\n",
      "tf.Tensor(1.111296, shape=(), dtype=float32)\n",
      "tf.Tensor(288.31833, shape=(), dtype=float32)\n",
      "tf.Tensor(2.8294804, shape=(), dtype=float32)\n",
      "tf.Tensor(99.847145, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7704889, shape=(), dtype=float32)\n",
      "tf.Tensor(113.83568, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1360645, shape=(), dtype=float32)\n",
      "tf.Tensor(1608.7372, shape=(), dtype=float32)\n",
      "tf.Tensor(30.746996, shape=(), dtype=float32)\n",
      "tf.Tensor(117.4132, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4886212, shape=(), dtype=float32)\n",
      "tf.Tensor(31134.203, shape=(), dtype=float32)\n",
      "tf.Tensor(355.9411, shape=(), dtype=float32)\n",
      "tf.Tensor(121.459435, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8497674, shape=(), dtype=float32)\n",
      "tf.Tensor(34.34991, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7784075, shape=(), dtype=float32)\n",
      "tf.Tensor(99.841805, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5092099, shape=(), dtype=float32)\n",
      "tf.Tensor(70.92178, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7800677, shape=(), dtype=float32)\n",
      "tf.Tensor(311.2546, shape=(), dtype=float32)\n",
      "tf.Tensor(6.2492733, shape=(), dtype=float32)\n",
      "tf.Tensor(25.870333, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0929341, shape=(), dtype=float32)\n",
      "tf.Tensor(65.17775, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1241525, shape=(), dtype=float32)\n",
      "tf.Tensor(231.67021, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0579252, shape=(), dtype=float32)\n",
      "tf.Tensor(98.297264, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5817534, shape=(), dtype=float32)\n",
      "tf.Tensor(201.82594, shape=(), dtype=float32)\n",
      "tf.Tensor(5.807151, shape=(), dtype=float32)\n",
      "tf.Tensor(133.7152, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2908163, shape=(), dtype=float32)\n",
      "tf.Tensor(51.05643, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4883169, shape=(), dtype=float32)\n",
      "tf.Tensor(99.84086, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2961714, shape=(), dtype=float32)\n",
      "tf.Tensor(315.78986, shape=(), dtype=float32)\n",
      "tf.Tensor(5.5071807, shape=(), dtype=float32)\n",
      "tf.Tensor(106.082085, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6368904, shape=(), dtype=float32)\n",
      "tf.Tensor(98.411644, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1299543, shape=(), dtype=float32)\n",
      "tf.Tensor(68.5628, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8781923, shape=(), dtype=float32)\n",
      "tf.Tensor(59.18214, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5881236, shape=(), dtype=float32)\n",
      "tf.Tensor(112.3209, shape=(), dtype=float32)\n",
      "tf.Tensor(2.388005, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for graph, label in tile_train_ds:\n",
    "    print(tf.reduce_max(label))\n",
    "    print(tf.reduce_mean(label))\n",
    "    # print(graph.node_sets['config']['normalizers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 20:20:03.551783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n",
      "2023-10-25 20:20:03.553251: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n",
      "2023-10-25 20:20:03.817543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype int64 and shape [237681,2]\n",
      "\t [[{{node Placeholder/_9}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Value: 4302.0\n",
      "Max Value: 31134202631.0\n",
      "Mean Value: 8084482.508666811\n",
      "Standard Deviation: 67850959.93257414\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect all results\n",
    "results = []\n",
    "\n",
    "for graph in tile_npz_dataset.train.get_graph_tensors_dataset():\n",
    "    result = tf.cast(graph.node_sets[\"config\"][\"runtimes\"], tf.float64) * tf.cast(\n",
    "        graph.node_sets[\"config\"][\"normalizers\"], tf.float64\n",
    "    )\n",
    "    results.append(result)\n",
    "\n",
    "# Convert to a tensor for easier manipulation\n",
    "results_tensor = tf.concat([tf.reshape(tensor, [-1]) for tensor in results], axis=0)\n",
    "\n",
    "# Calculate EDA metrics\n",
    "min_value = tf.reduce_min(results_tensor).numpy()\n",
    "max_value = tf.reduce_max(results_tensor).numpy()\n",
    "mean_value = tf.reduce_mean(results_tensor).numpy()\n",
    "std_dev = tf.math.reduce_std(results_tensor).numpy()\n",
    "\n",
    "# Display EDA metrics\n",
    "print(f\"Min Value: {min_value}\")\n",
    "print(f\"Max Value: {max_value}\")\n",
    "print(f\"Mean Value: {mean_value}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "\n",
    "# Plot a histogram\n",
    "plt.hist(results_tensor.numpy(), bins=1, color=\"blue\", alpha=0.7)\n",
    "plt.title(\"Distribution of Results\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_bins = np.logspace(np.log10(min_value), np.log10(max_value), 50)\n",
    "plt.hist(results_tensor.numpy(), bins=log_bins, color=\"blue\", alpha=0.7)\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"Logarithmic Distribution of Results\")\n",
    "plt.xlabel(\"Value (Log Scale)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "\n",
    "class _ConfigFeatureJoiner(abc.ABC):\n",
    "    \"\"\"Defines interface for joining config features with op nodes.\n",
    "    The implementations join features pre- or post-GNN, respectively, named as\n",
    "    `_EarlyJoin` and `_LateJoin`.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_op_node_features(self, graph: tfgnn.GraphTensor) -> tf.Tensor:\n",
    "        \"\"\"Should return feature matrix (or tensor) of op-nodes.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_penultimate_output(\n",
    "        self, pooled: tf.Tensor, unused_graph: tfgnn.GraphTensor\n",
    "    ) -> tf.Tensor:\n",
    "        \"\"\"Must return tensor with shape `[batch_size, num_configs, hidden_dim]`.\"\"\"\n",
    "        return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mlp(dims, hidden_activation, l2reg=1e-4, use_bias=True):\n",
    "    \"\"\"Helper function for multi-layer perceptron (MLP).\"\"\"\n",
    "    layers = []\n",
    "    for i, dim in enumerate(dims):\n",
    "        if i > 0:\n",
    "            layers.append(tf.keras.layers.Activation(hidden_activation))\n",
    "        layers.append(\n",
    "            tf.keras.layers.Dense(\n",
    "                dim,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
    "                use_bias=use_bias,\n",
    "            )\n",
    "        )\n",
    "    return tf.keras.Sequential(layers)\n",
    "\n",
    "\n",
    "class _OpEmbedding(tf.keras.Model):\n",
    "    \"\"\"Embeds GraphTensor.node_sets['op']['op'] nodes into feature 'op_e'.\"\"\"\n",
    "\n",
    "    def __init__(self, num_ops: int, embed_d: int, l2reg: float = 1e-4):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(\n",
    "            num_ops, embed_d, activity_regularizer=tf.keras.regularizers.l2(l2reg)\n",
    "        )\n",
    "\n",
    "    def call(self, graph: tfgnn.GraphTensor) -> tfgnn.GraphTensor:\n",
    "        op_features = dict(graph.node_sets[\"op\"].features)\n",
    "        op_features[\"op_e\"] = self.embedding_layer(\n",
    "            tf.cast(graph.node_sets[\"op\"][\"op\"], tf.int32)\n",
    "        )\n",
    "        return graph.replace_features(node_sets={\"op\": op_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self, output_dim, num_heads=1, attn_dropout=0.5, activation=tf.nn.relu\n",
    "    ):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attn_dropout = attn_dropout\n",
    "        self.activation = activation\n",
    "        self._att_ffn = _mlp([output_dim], self.activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Multi-head attention mechanism\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\",\n",
    "            shape=(input_shape[-1], self.output_dim * self.num_heads),\n",
    "            initializer=\"glorot_uniform\",\n",
    "        )\n",
    "        self.att_kernel = self.add_weight(\n",
    "            name=\"att_kernel\",\n",
    "            shape=(input_shape[-1], 1 * self.num_heads * 2),\n",
    "            initializer=\"glorot_uniform\",\n",
    "        )\n",
    "\n",
    "    def call(self, features, adjacency):\n",
    "        # Inputs are node features and adjacency matrix\n",
    "        outputs = []\n",
    "\n",
    "        for head in range(self.num_heads):\n",
    "            kernel_head = tf.slice(\n",
    "                self.kernel, [0, head * self.output_dim], [-1, self.output_dim]\n",
    "            )\n",
    "            att_head = tf.slice(self.att_kernel, [0, 2 * head], [-1, 2])\n",
    "\n",
    "            # Compute attention coefficients\n",
    "            attn_for_self = tf.matmul(features, att_head[:, 0:1])\n",
    "            attn_for_neighs = adjacency @ features @ att_head[:, 1:2]\n",
    "\n",
    "            attn_coeff = attn_for_self + tf.transpose(attn_for_neighs, [1, 0])\n",
    "            attn_coeff = self.activation(attn_coeff)\n",
    "            attn_coeff = tf.nn.experimental.stateless_dropout(\n",
    "                attn_coeff, rate=self.attn_dropout, seed=[1, 0]\n",
    "            )\n",
    "\n",
    "            attn_coeff = tf.exp(tf.clip_by_value(attn_coeff, -10, 10))\n",
    "            attn_coeff /= tf.reduce_sum(attn_coeff, axis=-1, keepdims=True)\n",
    "\n",
    "            # Compute node features\n",
    "            node_features = tf.matmul(features, kernel_head)\n",
    "            node_features = adjacency @ node_features\n",
    "            node_features = attn_coeff @ node_features\n",
    "\n",
    "            outputs.append(tf.expand_dims(node_features, axis=-1))\n",
    "\n",
    "        # Aggregate multi-head outputs\n",
    "        output = tf.reduce_mean(tf.concat(outputs, axis=-1), axis=-1)\n",
    "        return self._att_ffn(self.activation(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ResGCN(tf.keras.Model):\n",
    "    \"\"\"Implements GCN backbone with residual connections.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_ops: int,\n",
    "        num_gnns: int = 3,\n",
    "        mlp_layers: int = 2,\n",
    "        hidden_activation: str = \"leaky_relu\",\n",
    "        hidden_dim: int = 64,\n",
    "        op_embed_dim: int = 32,\n",
    "        directed: bool = False,\n",
    "        reduction: str = \"sum\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Assign parameters to instance variables\n",
    "        self._num_ops = num_ops\n",
    "        self._directed = directed\n",
    "        self._reduction = reduction\n",
    "        self._activation_fn = getattr(tf.nn, hidden_activation)\n",
    "\n",
    "        # Initialize operation embedding\n",
    "        self._op_embedding = _OpEmbedding(num_ops, op_embed_dim)\n",
    "        self._gat_layers = []\n",
    "        for _ in range(num_gnns):\n",
    "            self._gat_layers.append(\n",
    "                GATLayer(hidden_dim, num_heads=8, activation=self._activation_fn)\n",
    "            )\n",
    "        # Initialize pre and post networks\n",
    "\n",
    "        self._prenet = _mlp([hidden_dim, hidden_dim], self._activation_fn)\n",
    "        self._postnet = _mlp([2 * hidden_dim, hidden_dim, 1], self._activation_fn)\n",
    "\n",
    "    def call(self, graph: tfgnn.GraphTensor):\n",
    "        \"\"\"Perform a forward pass.\"\"\"\n",
    "        return self.forward(graph)\n",
    "\n",
    "    def forward(self, graph: tfgnn.GraphTensor) -> tfgnn.GraphTensor:\n",
    "        \"\"\"Define the forward propagation.\"\"\"\n",
    "\n",
    "        graph = self._op_embedding(graph)\n",
    "        x = self.get_op_node_features(graph)\n",
    "\n",
    "        am = implicit.AdjacencyMultiplier(graph, \"feed\")  # op -> op\n",
    "        am = am.add_eye().normalize_right()\n",
    "\n",
    "        x = self._prenet(x)\n",
    "\n",
    "        for gat_layer in self._gat_layers:\n",
    "            y = self._activation_fn(x)\n",
    "            y = gat_layer(y, am)\n",
    "            x += y\n",
    "\n",
    "        x = self._activation_fn(x)\n",
    "\n",
    "        # https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/api_docs/python/tfgnn/pool_nodes_to_context.md\n",
    "        pooled = tfgnn.pool_nodes_to_context(\n",
    "            graph, \"op\", self._reduction, feature_value=x\n",
    "        )\n",
    "        # print(pooled.shape)\n",
    "        pooled = self.get_penultimate_output(pooled, graph)\n",
    "\n",
    "        y = tf.squeeze(self._postnet(pooled), -1)\n",
    "\n",
    "        splited_y = tf.RaggedTensor.from_row_lengths(\n",
    "            values=y, row_lengths=graph.node_sets[\"config\"].sizes\n",
    "        )\n",
    "\n",
    "        return splited_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _LateJoin(_ConfigFeatureJoiner):\n",
    "    \"\"\"Joins module configuration features after applying GNN backbone.\"\"\"\n",
    "\n",
    "    def get_op_node_features(self, graph: tfgnn.GraphTensor) -> tfgnn.GraphTensor:\n",
    "        \"\"\"Retrieve operation node features.\"\"\"\n",
    "        return tf.concat(\n",
    "            [graph.node_sets[\"op\"][\"op_e\"], graph.node_sets[\"op\"][\"feats\"]], axis=-1\n",
    "        )\n",
    "\n",
    "    def get_penultimate_output(\n",
    "        self, pooled: tf.Tensor, graph: tfgnn.GraphTensor\n",
    "    ) -> tf.Tensor:\n",
    "        \"\"\"Work with pooled features.\"\"\"\n",
    "\n",
    "        config_feats = graph.node_sets[\"config\"][\"feats\"]\n",
    "        config_feats = tf.cast(config_feats, tf.float32)\n",
    "        config_size_per_graph = graph.node_sets[\"config\"].sizes\n",
    "\n",
    "        # Stack the pooled features for each configuration\n",
    "        repeated_pooled = tf.repeat(pooled, config_size_per_graph, axis=0)\n",
    "        pooled = tf.concat([repeated_pooled, config_feats], -1)\n",
    "\n",
    "        return pooled\n",
    "\n",
    "\n",
    "class LateJoinResGCN(_LateJoin, _ResGCN):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_ops: int,\n",
    "        num_gnns: int = 3,\n",
    "        mlp_layers: int = 2,\n",
    "        hidden_activation: str = \"leaky_relu\",\n",
    "        hidden_dim: int = 64,\n",
    "        op_embed_dim: int = 32,\n",
    "        directed: bool = False,\n",
    "        reduction: str = \"sum\",\n",
    "    ):\n",
    "        # Initialize the _ResGCN superclass with the provided parameters\n",
    "        _ResGCN.__init__(\n",
    "            self,\n",
    "            num_ops,\n",
    "            num_gnns,\n",
    "            mlp_layers,\n",
    "            hidden_activation,\n",
    "            hidden_dim,\n",
    "            op_embed_dim,\n",
    "            directed,\n",
    "            reduction,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowdown_metric(y_true, y_pred, k=5):\n",
    "    # Get the indices of the top-k predictions\n",
    "    top_k_indices = tf.argsort(y_pred, direction=\"ASCENDING\")[:k]\n",
    "    # Get the best runtime of the top-k predictions\n",
    "    best_runtime_top_k = tf.reduce_min(tf.gather(y_true, top_k_indices))\n",
    "    # Get the best runtime of all configurations\n",
    "    best_runtime_all = tf.reduce_min(y_true)\n",
    "    # Compute the metric\n",
    "    metric_value = 2 - best_runtime_top_k / best_runtime_all\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowdown_metric_single(y_true_single, y_pred_single, k=5):\n",
    "    # Ensure y_true_single and y_pred_single are tensors (they'll be passed as tensors from the ragged map_fn)\n",
    "    y_true_single = tf.convert_to_tensor(y_true_single)\n",
    "    y_pred_single = tf.convert_to_tensor(y_pred_single)\n",
    "    # Get the indices of the top-k predictions\n",
    "    top_k_indices = tf.argsort(y_pred_single, direction=\"ASCENDING\")[:k]\n",
    "    # Get the best runtime of the top-k predictions\n",
    "    best_runtime_top_k = tf.reduce_min(tf.gather(y_true_single, top_k_indices))\n",
    "    # Get the best runtime of all configurations\n",
    "    best_runtime_all = tf.reduce_min(y_true_single)\n",
    "    # Compute the metric\n",
    "    metric_value = 2 - best_runtime_top_k / best_runtime_all\n",
    "\n",
    "    return metric_value\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def slowdown_metric_ragged(y_true, y_pred, k=5):\n",
    "    # Map the slowdown_metric_single function across the ragged dimensions\n",
    "    metric_values = tf.map_fn(\n",
    "        lambda x: slowdown_metric_single(x[0], x[1], k),\n",
    "        (y_true, y_pred),\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "    return tf.reduce_min(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LateJoinResGCN(tile_npz_dataset.num_ops, directed=True)\n",
    "\n",
    "loss = tfr.keras.losses.MeanSquaredLoss(ragged=True)  # (temperature=10)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=0.5)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=opt,\n",
    "    # metrics=[slowdown_metric_ragged],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"best_weights.h5\",  # Path to save the model file\n",
    "    monitor=\"val_loss\",  # Quantity to monitor\n",
    "    verbose=1,  # Verbosity mode, 1 means print logs\n",
    "    save_best_only=True,  # Only save the best model\n",
    "    mode=\"min\",  # 'min' mode means the callback will try to minimize the 'monitor' quantity\n",
    "    save_weights_only=True,  # Only save the weights, not the entire model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    tile_train_ds,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=tile_valid_ds,\n",
    "    validation_freq=1,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "count = 0\n",
    "model.load_weights(\"best_weights.h5\")\n",
    "for graph in tqdm.tqdm(\n",
    "    tile_npz_dataset.train.get_graph_tensors_dataset(),\n",
    "    total=tile_npz_dataset.train.tile_id.shape[-1],\n",
    "    desc=\"CHECK\",\n",
    "):\n",
    "    graph, label = pair_tile_graph_with_label(graph)\n",
    "    result = slowdown_metric_ragged(label, model(graph))\n",
    "    if result < 0.7:\n",
    "        count += 1\n",
    "        print(graph.node_sets[\"g\"][\"tile_id\"][0].numpy().decode())\n",
    "        print(result)\n",
    "    # print(result)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = 20\n",
    "best_params = None  # Stores parameters corresponding to best validation OPA, to restore to them after training.\n",
    "# best_val_opa = -1  # Tracks best validation OPA\n",
    "best_val_loss = 100\n",
    "best_val_at_epoch = -1  # At which epoch.\n",
    "epochs = 200  # Total number of training epochs.\n",
    "\n",
    "for i in range(epochs):\n",
    "    history = model.fit(\n",
    "        tile_train_ds,\n",
    "        epochs=1,\n",
    "        verbose=1,\n",
    "        validation_data=tile_valid_ds,\n",
    "        validation_freq=1,\n",
    "    )\n",
    "\n",
    "    train_loss = history.history[\"loss\"][-1]\n",
    "    # train_opa = history.history[\"slowdown_metric\"][-1]\n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "    # val_opa = history.history[\"val_slowdown_metric\"][-1]\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_at_epoch = i\n",
    "        best_params = {v.ref: v + 0 for v in model.trainable_variables}\n",
    "        print(\" * [@%i] Validation (NEW BEST): %s\" % (i, str(val_loss)))\n",
    "    # elif early_stop > 0 and i - best_val_at_epoch >= early_stop:\n",
    "    #     print(\n",
    "    #         \"[@%i] Best accuracy was attained at epoch %i. Stopping.\"\n",
    "    #         % (i, best_val_at_epoch)\n",
    "    #     )\n",
    "    #     break\n",
    "\n",
    "# Restore best parameters.\n",
    "print(\"Restoring parameters corresponding to the best validation OPA.\")\n",
    "assert best_params is not None\n",
    "for v in model.trainable_variables:\n",
    "    v.assign(best_params[v.ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.56603754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.891763, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8859724, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70332336, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49178374, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06557512, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38277078, shape=(), dtype=float32)\n",
      "tf.Tensor(0.62703955, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68694985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35003734, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5692153, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48838174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56305015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.93455136, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59631455, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39908266, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6211399, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.30999947, shape=(), dtype=float32)\n",
      "tf.Tensor(0.74910426, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42077732, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33036554, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18858111, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6470195, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6073942, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30717468, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45403123, shape=(), dtype=float32)\n",
      "tf.Tensor(0.58992934, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.09375024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07993555, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2975235, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.010467052, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10352957, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.0777235, shape=(), dtype=float32)\n",
      "tf.Tensor(0.051450253, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08785105, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34230733, shape=(), dtype=float32)\n",
      "tf.Tensor(0.028822184, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24360347, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.20053673, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6437453, shape=(), dtype=float32)\n",
      "tf.Tensor(0.74421453, shape=(), dtype=float32)\n",
      "tf.Tensor(-1.0667825, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.6677587, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for graph_batch, runtimes in tile_valid_ds:\n",
    "    result = slowdown_metric_ragged(runtimes, model(graph_batch))\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 18:08:53.040522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n",
      "2023-10-25 18:08:53.042177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_7' with dtype int32\n",
      "\t [[{{node args_7}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   Running inference on test set ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|                                                         | 0/844 [00:00<?, ?it/s]2023-10-25 18:08:53.116414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype int64 and shape [31747,2]\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "Inference: 100%|███████████████████████████████████████████████| 844/844 [02:40<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   ***  Wrote inference_tile_xla.csv \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "model.load_weights(\"best_weights.h5\")\n",
    "output_csv_filename = f\"inference_tile_{SOURCE}.csv\"\n",
    "print(\"\\n\\n   Running inference on test set ...\\n\\n\")\n",
    "test_rankings = []\n",
    "\n",
    "assert tile_npz_dataset.test.tile_id is not None\n",
    "for graph in tqdm.tqdm(\n",
    "    tile_npz_dataset.test.get_graph_tensors_dataset(),\n",
    "    total=tile_npz_dataset.test.tile_id.shape[-1],\n",
    "    desc=\"Inference\",\n",
    "):\n",
    "    h = model.forward(graph)\n",
    "    all_scores = h[0]\n",
    "    tile_id = graph.node_sets[\"g\"][\"tile_id\"][0].numpy().decode()\n",
    "    sorted_indices = (\n",
    "        tf.strings.join(tf.strings.as_string(tf.argsort(all_scores)[:5]), \";\")\n",
    "        .numpy()\n",
    "        .decode()\n",
    "    )\n",
    "    test_rankings.append((tile_id, sorted_indices))\n",
    "\n",
    "with tf.io.gfile.GFile(output_csv_filename, \"w\") as fout:\n",
    "    fout.write(\"ID,TopConfigs\\n\")\n",
    "    for graph_id, ranks in test_rankings:\n",
    "        fout.write(f\"tile:{SOURCE}:{graph_id},{ranks}\\n\")\n",
    "print(\"\\n\\n   ***  Wrote\", output_csv_filename, \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
